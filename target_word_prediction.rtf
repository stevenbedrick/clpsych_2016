{\rtf1\ansi\uc1\deff0\deflang1024
{\fonttbl{\f0\fnil\fcharset0 Times New Roman;}
{\f1\fnil\fcharset0 Arial;}
{\f2\fnil\fcharset0 Arial;}
{\f3\fnil\fcharset0 Courier New;}
{\f4\fnil\fcharset0 Zapf Chancery;}
{\f5\fnil\fcharset0 STIXGeneral;}
}
{\colortbl;
\red0\green0\blue0;
\red0\green0\blue255;
\red0\green255\blue255;
\red0\green255\blue0;
\red255\green0\blue255;
\red255\green0\blue0;
\red255\green255\blue0;
\red255\green255\blue255;
}
{\stylesheet
{\s0\qj\widctlpar\f0\fs22 \snext0 Normal;}
{\cs10 \additive\ssemihidden Default Paragraph Font;}
{\s1\qc\sb240\sa120\keepn\f0\b\fs40 \sbasedon0\snext0 Part;}
{\s2\ql\sb240\sa120\keepn\f0\b\fs40 \sbasedon0\snext0 heading 1;}
{\s3\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext0 heading 2;}
{\s4\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext0 heading 3;}
{\s5\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 4;}
{\s6\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 5;}
{\s7\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 6;}
{\s8\qr\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext8 rightpar;}
{\s9\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext9 centerpar;}
{\s10\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext10 leftpar;}
{\s11\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equation;}
{\s12\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationNum;}
{\s13\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationAlign;}
{\s14\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationAlignNum;}
{\s15\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationArray;}
{\s16\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationArrayNum;}
{\s17\ql\sb120\sa120\keep\widctlpar\f0\fs20 \sbasedon0\snext0 theorem;}
{\s18\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 bitmapCenter;}
{\s20\qc\sb240\sa240\b\f0\fs36 \sbasedon0\snext21 Title;}
{\s21\qc\sa120\f0\fs22 \sbasedon0\snext0 author;}
{\s22\ql\tqc\tx4536\tqr\tx9072\f0\fs20 \sbasedon0\snext22 footer;}
{\s23\ql\tqc\tx4536\tqr\tx9072\f0\fs20 \sbasedon0\snext23 header;}
{\s30\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 caption;}
{\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext0 Figure;}
{\s32\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext32 Table;}
{\s33\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext33 Tabular;}
{\s34\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext34 Tabbing;}
{\s35\qj\li1024\ri1024\fi340\widctlpar\f0\fs20 \sbasedon0\snext35 Quote;}
{\s38\ql\widctlpar\f3\fs22 \snext38 verbatim;}
{\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext46 List;}
{\s47\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext47 List 1;}
{\s50\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 latex picture;}
{\s51\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 subfigure;}
{\s61\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext62 bibheading;}
{\s62\ql\fi-567\li567\sb0\sa0\f0\fs20 \sbasedon0\snext62 bibitem;}
{\s64\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext64 endnotes;}
{\s65\ql\fi-113\li397\lin397\f0\fs22 \sbasedon0\snext65 footnote text;}
{\s66\qj\fi-170\li454\lin454\f0\fs22 \sbasedon0\snext66 endnote text;}
{\cs62\super \additive\sbasedon10 footnote reference;}
{\cs63\super \additive\sbasedon10 endnote reference;}
{\s67\ql\sb60\sa60\keepn\f0\fs22 \sbasedon0\snext67 acronym;}
{\s70\qc\sa120\b\f0\fs22 \sbasedon0\snext71 abstract title;}
{\s71\qj\li1024\ri1024\fi340\widctlpar\f0\fs22 \sbasedon0\snext0 abstract;}
{\s80\ql\sb240\sa120\keepn\f0\b\fs20 \sbasedon0\snext0 contents_heading;}
{\s81\ql\li425\tqr\tldot\tx8222\sb240\sa60\keepn\f0\fs22\b \sbasedon0\snext82 toc 1;}
{\s82\ql\li512\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs22 \sbasedon0\snext83 toc 2;}
{\s83\ql\li1024\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs22 \sbasedon0\snext84 toc 3;}
{\s84\ql\li1536\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs22 \sbasedon0\snext85 toc 4;}
{\s85\ql\li2048\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs22 \sbasedon0\snext86 toc 5;}
{\s86\ql\li2560\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs22 \sbasedon0\snext86 toc 6;}
}
{\info
{\title Original file was target_word_prediction.tex}
{\doccomm Created using latex2rtf 2.3.8 r1240 (released June 16 2014) on Thu Mar  3 22:02:28 2016
}
}
{\footer\pard\plain\f0\fs22\qc\chpgn\par}
\paperw12280\paperh15900\margl2520\margr2560\margt2540\margb1940\pgnstart0\widowctrl\qj\ftnbj\f0\aftnnar
{\pard\plain\s20\qc\sb240\sa240\b\f0\fs36\sl240\slmult1 \fi0 Target word prediction and paraphasia classification in spoken discourse\par
\pard\plain\s21\qc\sa120\f0\fs22\sl240\slmult1 \fi340 [\par
\pard\plain\s21\qc\sa120\f0\fs22\sl240\slmult1 \fi340 \chdate \par
{\pard\plain\s70\qc\sa120\b\f0\fs22\sl240\slmult1 \fi340 Abstract\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \li1024\ri1024\fi340 \par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \li1024\ri1024\fi340 We present a system for automatically detecting and classifying phonologically anomalous productions in the speech of individuals with aphasia. Working from transcribed discourse samles, our system identifies neologisms, and uses a combination of string alignment and language models to produce a lattice of plausible words that the speaker may have intended to produce. We then score this lattice according to various features, and attempt to determine whether the anomalous production represented a phonemic error or a genuine neologism. This approach has the potential to be expanded to consider other types of paraphasic errors, and could be applied to a wide variety of screening and therapeutic applications.\par
}\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb360 \fi0 1  Introduction\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Aphasia is a neuropsychological condition in which an individual\rquote s ability to produce or comprehend language is compromised. It can be caused by a number of different underlying pathologies, but can generally be traced back to physical damage to the individual\rquote s brain: tissue damage following ischemic or hemorrhagic stroke, lesions caused by a traumatic brain injury or infection, etc. It can also be associated with various neurodegenerative diseases, as in the case of Primary Progressive Aphasia. According to the National Institute of Neurological Disorders and Stroke, approximately 1,000,000 people in the United States suffer from aphasia 
[{\field{\*\fldinst{\lang1024 REF BIB_National_Institute_of_Neurological_Disorders_and_Stroke_2014la \\* MERGEFORMAT }}{\fldrslt{{{{National Institute of Neurological Disorders and Stroke}}}2014}}}
], and aphasia is a common consequence of strokes (prevalence estimates for aphasia among stroke patients vary, but are typically in the neighborhood of 30% 
[{\field{\*\fldinst{\lang1024 REF BIB_Engelter_2006da \\* MERGEFORMAT }}{\fldrslt{{Engelter et al.}2006}}}
]).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 {\i Anomia} is a the inability to access and retrieve words during language production, and is a common manifestation of aphasia 
[{\field{\*\fldinst{\lang1024 REF BIB_Goodglass_1997ys \\* MERGEFORMAT }}{\fldrslt{{Goodglass and Wingfield}1997}}}
]. An anomic individual will experience difficulty producing words and naming items, which can cause substantial difficulties in day-to-day communication. Additionally, long-term communication difficulties associated with aphasia in general have been shown to affect the psychological well-being of people with aphasia as well as their families 
[{\field{\*\fldinst{\lang1024 REF BIB_doi_10_1080_02687030244000707 \\* MERGEFORMAT }}{\fldrslt{{Cruice et al.}2003}}}, {\field{\*\fldinst{\lang1024 REF BIB_Gaete_2008jr \\* MERGEFORMAT }}{\fldrslt{{Gaete and Bogousslavsky}2008}}}, {\field{\*\fldinst{\lang1024 REF BIB_vanDijk_2015gz \\* MERGEFORMAT }}{\fldrslt{{van Dijk et al.}2015}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 The process of screening for, diagnosing, and assessing anomia is typically manual in nature, and requires substantial time, labor, and expertise. Compared to other neuropsychological assessment instruments, aphasia-related assessments are particularly difficult to computerize, as they typically depend on subtle and complex linguistic judgments about the phonological and semantic similarity of words, and also require the examiner to interpret phonologically disordered speech. Furthermore, the most commonly used assessments focus for practical reasons on relatively constrained tasks such as picture naming, which may lack ecological validity 
[{\field{\*\fldinst{\lang1024 REF BIB_Mayer_2003kp \\* MERGEFORMAT }}{\fldrslt{{Mayer and Murray}2003}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 In this work, we describe an approach to automatically detecting and analyzing certain categories of word production errors characteristic of anomia in connected speech. Our approach is a first step towards an automated anomia assessment tool that could be used cost effectively in both clinical and research settings,{\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} As in the computer-administered (but manually-scored) assessments developed by Fergadiotis and colleagues 
[{\field{\*\fldinst{\lang1024 REF BIB_Fergadiotis_2015gp \\* MERGEFORMAT }}{\fldrslt{{Fergadiotis et al.}2015}}}, {\field{\*\fldinst{\lang1024 REF BIB_Hula_2015kz \\* MERGEFORMAT }}{\fldrslt{{Hula et al.}2015}}}
]. }
 and could also be applied to other disorders of speech production. The method we propose uses statistical language models to identify possible errors, and employs a phonologically-informed edit distance model to determine phonological similarity between the subject\rquote s utterance and a set of plausible \ldblquote intended words.\rdblquote  We then apply machine learning techniques to determine which of several categories a given erroneous production may fall into. We show XXXX \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_anomia_and_paraphasias}1.1{\*\bkmkend BMsub_anomia_and_paraphasias}  Anomia and Paraphasias\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Anomia can take several different forms, but in this work we are concerned with {\i paraphasias}, which are unintended errors in word production.{\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} Note that individuals {\i without} any sort of language disorder do occasionally produce errors in their speech; this fact has led to a truly shocking amount of study by linguists. Frisch & Wright {Frisch:wh} provide a reasonable overview of the background and phonology of the phenomenon.}
 There are several categories of paraphasic error. {\i Semantic errors} arise when an individual unintentionally produces a semantically-related word to their original, intended word (their \ldblquote target word\rdblquote ). A classic semantic error would be saying \ldblquote cat\rdblquote  when one intended to say \ldblquote dog.\rdblquote \par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 {\i Phonemic} (sometimes called \ldblquote formal\rdblquote ) errors occur when the speaker produces an unrelated word that is {\i phonemically related} to their target: \ldblquote mat\rdblquote  for \ldblquote cat\rdblquote , for example. It is also possible for an erroneous production to be {\i mixed}, that is both semantically and phonemically related to the target word: \ldblquote rat\rdblquote  for \ldblquote cat.\rdblquote  Individuals with anomia also produce {\i unrelated} errors, which are words that are neither semantically or phonemically related to their intended target word: for example, producing \ldblquote skis\rdblquote  instead of \ldblquote zipper.\rdblquote \par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Each of these categories shares the commonality that the word produced by the individual is a \ldblquote real\rdblquote  word. There is another family of anomic errors, {\i neologisms}, in which the individual produces {\i non-word} productions. A neologistic production may be phonemically related to the target, but containing phonological errors: \ldblquote [d\u201?\u8216?\u201?\u170?no\u202?\u352?s\u201?\u8221?\u201?\u185?]\rdblquote  for \ldblquote dinosaur.\rdblquote  These are often referred t as {\i phonological} paraphasias. Alternatively, the individual may produce {\i abstruse neologisms}, in which the produced phonemes bear no discernable similarity to any \ldblquote real\rdblquote  lexical item (\ldblquote [\u195?\u166?pm\u201?\u8482?l]\rdblquote  for \ldblquote comb\rdblquote {\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} This example was taken from a corpus of responses to a confrontation naming test 
[{\field{\*\fldinst{\lang1024 REF BIB_Mirman_2010cd \\* MERGEFORMAT }}{\fldrslt{{Mirman et al.}2010}}}
], in which the subject is shown a picture and required to name its contents. As such, in the case of this specific error, we have {\i a priori} knowledge of what the target word \ldblquote should\rdblquote  have been. Obviously, in a more naturalistic task or setting, we would not have this advantage.}
).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 A full discussion of the theoretical basis for this typology of paraphasias is beyond the scope of this paper. That said, it is worth nothing that the standard model explaining these sorts of anomic errors is Dell\rquote s two-step word production model 
[{\field{\*\fldinst{\lang1024 REF BIB_Dell_1997wj \\* MERGEFORMAT }}{\fldrslt{{Dell et al.}1997}}}, {\field{\*\fldinst{\lang1024 REF BIB_Dell_1986vk \\* MERGEFORMAT }}{\fldrslt{{Dell}1986}}}
]. In Dell\rquote s model, language production occurs in two primary phases. First, the speaker forms some semantic representation of what they wish to say, and accesses the lemma form of that word. Then, those selected lexical items are translated into spoken language.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Under this model, then, there are two primary ways that paraphasic productions can occur: the \ldblquote wrong\rdblquote  lexical item may be selected (as in the case of a semantic error or an unrelated error), and/or the translation process from lexical item to produced speech may go awry, resulting in formal (or other such phonemic) errors. When problems occur in both steps of the process, we see a mixed error (i.e., an error containing both phonological and semantic components).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 The present work focuses exclusively on neologisms, both of the phonological variety as well as the abstruse variety. However, our fundamental approach can be extended to include other forms, as described in section\~{\field{\*\fldinst{\lang1024 REF BMsub_future_work \\* MERGEFORMAT }}{\fldrslt{5.1}}}.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Typical methods of diagnosing, staging, and otherwise characterizing anomia involve determining the number and kinds of paraphasias produced by an individual while undergoing some structured language elicitation process, for example a confrontation naming test (see 
[{\field{\*\fldinst{\lang1024 REF BIB_Kendall_2013hm \\* MERGEFORMAT }}{\fldrslt{{Kendall et al.}2013}}}
] and 
[{\field{\*\fldinst{\lang1024 REF BIB_Brookshire_2014fa \\* MERGEFORMAT }}{\fldrslt{{Brookshire et al.}2014}}}
] for examples of such a study). As alluded to previously, producing these counts and classifications is a complex and laborious process. Furthermore, it is also often an inherently subjective process: are \ldblquote carrot\rdblquote  and \ldblquote banana\rdblquote  semantically related? What about \ldblquote hose\rdblquote  and \ldblquote rope\rdblquote ?\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Reliability estimates of expert human performance at paraphasia classification in confrontation naming scenarios reflect the difficulty in this task. One recent study reported a kappa-equivalent score of 0.76 \emdash  a score that that is certainly acceptable, but that leaves much room for disagreement on the status of specific erroneous productions 
[{\field{\*\fldinst{\lang1024 REF BIB_Minkina_2015dz \\* MERGEFORMAT }}{\fldrslt{{Minkina et al.}2015}}}
]. Other reported scores fall in a similar range 
[{\field{\*\fldinst{\lang1024 REF BIB_doi_10_1080_02687038_2014_973359 \\* MERGEFORMAT }}{\fldrslt{{Kristensson et al.}2015}}}
], including when the productions are from neurotypical individuals 
[{\field{\*\fldinst{\lang1024 REF BIB_doi_10_1080_02687038908249023 \\* MERGEFORMAT }}{\fldrslt{{Nicholas et al.}1989}}}
]. Automating this aspect of the task would not only improve efficiency, but would also decrease scoring variability.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Having a reliable, automated method to analyze paraphasic errors would also expand the scope of what is currently possible in terms of assessment methodologies. Confrontation naming tests are often used (both in the clinic as well as in research settings) not because they are thought to optimally characterize the speech capabilities of their subjects, but rather out of concerns regarding feasibility of scoring. Naturalistic language samples may be more ecologically valid, but such data present a very complex and challenging scoring scenario (for example, see 
[{\field{\*\fldinst{\lang1024 REF BIB_Nicholas_1993wl \\* MERGEFORMAT }}{\fldrslt{{Nicholas and Brookshire}1993}}}, {\field{\*\fldinst{\lang1024 REF BIB_Berndt_2000aa \\* MERGEFORMAT }}{\fldrslt{{Berndt et al.}2000}}}, {\field{\*\fldinst{\lang1024 REF BIB_Rochon_2000js \\* MERGEFORMAT }}{\fldrslt{{Rochon et al.}2000}}}
]), and so practitioners often eschew them in favor of simpler, more structured assessments.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Notably, the approach we outline in this paper is explicitly designed to work on samples of natural, connected speech\emdash  though it did grow out of work that the authors are currently doing on automated confrontation naming test scoring. It is our hope that, by enabling automated calculation of error frequencies and types on narrative speech, we might make using such material far easier in practice than it is today.\par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 2  Methods\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Our overall approach was as follows. Beginning with transcribed narrative samples from people with aphasia, we used a corpus-driven method to identify possible neologisms in the subjects\rquote  speech. Once we have identified candidate neologisms, we must Next, for each neologism, we used an n-gram language model to build a weighted lattice of plausible \ldblquote target words\rdblquote  (see figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sample_lattice \\* MERGEFORMAT }}{\fldrslt{2.4}}} for an unweighted example of such a lattice). For each sentence, we then compute a metric of phonological similarity between the erroneous utterance produced by the subject and the candidate target words. We then attempt to classify this production as either a phonological paraphasia or an abstruse neologism. We will describe each step of the process in detail below, beginning with our the data set.\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_dataset}2.1{\*\bkmkend BMsub_dataset}  Dataset\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 For the work described in this paper, we relied on the AphasiaBank project 
[{\field{\*\fldinst{\lang1024 REF BIB_MacWhinney_2011er \\* MERGEFORMAT }}{\fldrslt{{MacWhinney et al.}2011}}}
], which has assembled a large database of transcribed interactions between examiners and people with aphasia, nearly all of whom have suffered a stroke. Notably, AphasiaBank also includes some number of transcribed sessions with neurotypical controls. Each interaction follows a common protocol and script, and is transcribed in great detail using a standardized set of annotation guidelines. The transcripts include word-level error codes, according to a spectacularly detailed taxonomy of errors and associated annotations. Erroneous productions are not simply flagged as erroneous. In the case of semantic, formal, and phonemic errors, the word-level annotations include a \ldblquote best guess\rdblquote  on the part of the transcriber as to what the speaker\rquote s intended production may have been. In the case of non-lexical productions (phonemic errors, neologisms, etc.), the annotations include an IPA transcription of the subject\rquote s precise utterance. In some cases, the transcribers include information about gestures and other non-verbal communication that the subjects may have produced. The transcripts are stored in the CLAN (Computerized Language Analysis) format 
[{\field{\*\fldinst{\lang1024 REF BIB_MacWhinney_2000aa \\* MERGEFORMAT }}{\fldrslt{{MacWhinney}2000}}}
], and are therefore highly amenable to automated analysis.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Each transcribed session consists of a prescribed sequence of language elicitation activities, including a set of personal narratives (e.g., \ldblquote Tell me a story about an important event that happened to you\rdblquote , \ldblquote Do you remember when you had your stroke? Please tell me about it.\rdblquote ), standardized picture description tasks, a story retelling task (involving the story of {\i Cinderella}), and a procedural discourse task (in which the subjects are asked to describe for the examiner the process of making a peanut-butter and jelly sandwich).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 In addition to the narrative sessions, each subject\rquote s data also includes the results of a battery of standardized assessments, including a confrontation naming test, the Aphasia Quotient sub-test of the Western Aphasia Battery, and so forth.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 We obtained an up-to-date copy of the AphasiaBank database, and applied a series of minor normalizations as a first step in our analytical pipeline. First, we harmonized the names by which examiners referred to the various tasks, as this varied slightly from study site to study site (e.g., one site referred to the \ldblquote Important event\rdblquote  task, while another referred to \ldblquote Important_Event\rdblquote ), and dealt with several other such minor orthographic irregularities across study sites.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Less trivially, we collapsed certain word-level error codes. As an example, the AphasiaBank protocol includes a special annotation used to indicate that a given neologism error represents an utterance that recurs frequently within a particular subject, as occasionally happens with individuals with aphasia (e.g., an individual might repeatedly utter the phonemes XXX). Since the present analysis was not concerned with this aspect of the transcripts, we collapsed instances of this and several other similarly specific error codes into their more general forms.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Certain non-standard productions that are nevertheless typical of a dialect (\ldblquote gotta\rdblquote , etc.) are occasionally labeled by the AphasiaBank transcribers as such, along with their \ldblquote canonical\rdblquote  form (e.g. \ldblquote got to\rdblquote  for \ldblquote gotta\rdblquote ). In these cases, we replaced the \ldblquote true\rdblquote  production with its canonical form. This was motivated by the fact that we would be using language models that were not explicitly trained on conversational speech, and we did not want incidental dialect usage of this sort to complicate matters.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Finally, we transformed the human-generated IPA representation of non-word productions into a relatively impoverished graphemic representation (using the inverse of the process described in section\~{\field{\*\fldinst{\lang1024 REF BMsub_phonological_similarity \\* MERGEFORMAT }}{\fldrslt{2.5}}}). Our purpose in doing this was to simulate a scenario where we did {\i not} have high-quality human-produced phonetic transcriptions. Obviously, one major obstacle to using narrative samples in any sort of clinical assessment is the need for transcription. Two of the most plausible solutions to this problem are automatic speech recognition (ASR){\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} See Fraser et al. {fraser-EtAl:2015:NAACL-HLT} for a detailed discussion of the implications of using ASR on the speech of individuals with aphasia}
 and/or the use of {\i non-expert} transcribers to produce \ldblquote quick-and-dirty\rdblquote  transcripts (perhaps via Amazon Mechanical Turk, or some other such crowd-sourced platform).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 In the case of ASR-derived transcripts, we would presumably have access to some sort of phonetic representation of what was said by the subject, though this representation would almost certainly be incomplete and error-prone (ASR systems are particularly bad at handling non-word productions of any sort). Even in the less-challenging case of transcripts produced by non-expert humans, we would of course not find the professional-quality IPA transcriptions found in the AphasiaBank database. We would instead be working with a \ldblquote best effort\rdblquote  attempt at rendering what the transcriber heard the subject produce.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 We therefore anticipate that in any sort of \ldblquote real-world\rdblquote  scenario of use, our system will need to operate with imperfect phonetic information. As such, for this study, we modified the phonetic transcripts found in the AphasiaBank data to something approximating \ldblquote standard\rdblquote  English orthography.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 We next chose two of the AphasiaBank personal narrative tasks\emdash  describing the individual\rquote s stroke, and telling the story of an important event that happened sometime during the individual\rquote s life\emdash  to work with, and excerpted the intervals containing those sections from each transcript. This resulted in XXX sentences from YYY individuals. We then identified sentences containing instances of our errors of interest: phonological paraphasia (AphasiaBank codes \ldblquote p:n\rdblquote , \ldblquote p:m\rdblquote , and \ldblquote n:k\rdblquote ) or abstruse neologism (\ldblquote n:uk\rdblquote ). Note that the distribution of errors within sentences was relatively Zipfian, in that the majority of error-containing sentences contained a single error, followed somewhat distantly by sentences containing two errors, with a relatively steep dropoff thereafter. For the present study, we restricted our analysis to sentences that contained either one or two errors.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Our reasoning for this restriction was that we do not presently have a theoretically-informed model of what, if any, relationship there may be between multiple errors within a sentence. However, it seems quite likely that the errors occurring in a sentence containing (for instance) five paraphasic errors might be somehow related to one another. We anticipate exploring this phenomenon in the future (see section\~{\field{\*\fldinst{\lang1024 REF BMsub_future_work \\* MERGEFORMAT }}{\fldrslt{5.1}}}).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Our final data set consisted of XXX sentences from YYY individuals, containing errors from ZZZ distinct categories. \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_identification_of_neologisms}2.2{\*\bkmkend BMsub_identification_of_neologisms}  Identification of Neologisms\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 We next turned to the question of identifying neologisms in our sentences. Simply using a standard dictionary to determine lexicality could result in numerous \ldblquote false positives,\rdblquote  driven largely by proper names of people, brands, etc. To avoid this, we used the SUBTLEX-US corpus 
[{\field{\*\fldinst{\lang1024 REF BIB_Brysbaert_2009du \\* MERGEFORMAT }}{\fldrslt{{Brysbaert and New}2009}}}
] to identify neologisms. SUBTLEX-US was build using subtitles from English-language television shows and movies, and Brysbaert and New have demonstrated that it correlates with a number of psycholinguistic behavior measures (most notably, naming latencies) better than better-known frequency norms such as those derived from the Brown corpus or CELEX-2.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Note that, in the present analysis, this step in our pipeline was something of a contrived exercise, as (thanks to the detailed annotations present in the AphasiaBank transcripts) we already \ldblquote knew\rdblquote  which tokens represented neologisms. However, in a \ldblquote real-world\rdblquote  scenario, when we did {\i not} know {\i a priori} which tokens represented non-word productions, this step would be of particular importance, and we wished to simulate it with as much fidelity as possible. Furthermore, recall that while the present analysis only concerns itself with non-word productions, there are a number of paraphasia types in which a valid word is produced. Determining which productions represent a semantic or formal error is much more complex than simply performing a corpus lookup. We expect this stage of our pipeline to grow in complexity in the future.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Upon identifying a possible non-word production, recall that our next goal is to determine whether it represents a {\i phonemic} error (substituting \ldblquote [d\u201?\u8216?\u201?\u170?no\u202?\u352?s\u201?\u8221?\u201?\u185?]\rdblquote  for \ldblquote dinosaur\rdblquote ) or an {\i abstruse neologism} (a completely novel sequence of phonemes that does not correspond to an actual word). To help accomplish this, we use a language model to identify plausible words that {\i could} fit in the slot occupied by the erroneous production, and produce a lattice of these candidate target words (i.e., words that the subject may have been intending to produce, given what we know about the context in which they were speaking).\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_language_model_construction}2.3{\*\bkmkend BMsub_language_model_construction}  Language Model Construction\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Our language models for this study were built using the New York Times section of the Gigaword newswire corpus. We tokenized using the standard Penn Treebank tokenizer, left stopwords intact, and case-folded all sentences to upper-case. Cardinal numbers were collapsed into a category token, as were ordinal numbers and dates (each category was given its own token). We used the the OpenGrm-NGram language modeling toolkit 
[{\field{\*\fldinst{\lang1024 REF BIB_RoarkOpenGRM \\* MERGEFORMAT }}{\fldrslt{{Roark et al.}2012}}}
] to build the language models themselves, using an n-gram order of 4, with XXX smoothing. We investigated two different language model approaches. In the first approach, we trained our models on the totality of the New York Times data. However, given that many of the AphasiaBank narrative tasks consist of fairly topic-constrained language (e.g., the Cinderella retelling, the personal narrative about the subject\rquote s stroke, etc.), we hypothesized that we would get better results (i.e., higher-quality word predictions) if we could train our models on a more focused set of data.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 To accomplish this, we used the Gensim topic modeling package 
[{\field{\*\fldinst{\lang1024 REF BIB_rehurek_lrec \\* MERGEFORMAT }}{\fldrslt{{{\u344R}eh{\u367u}{\u345r}ek and Sojka}2010}}}
] to train a Latent Dirichlet Allocation topic model 
[{\field{\*\fldinst{\lang1024 REF BIB_Blei_2003_LDA_944919_944937 \\* MERGEFORMAT }}{\fldrslt{{Blei et al.}2003}}}
] on the entire New York Times data set. For the present analysis, we instructed the model to use 20 topics. We next projected the text of each of the narrative samples into the topic space described by the model, and calculated the centroids for each of the narrative task. This gave us, for example, the estimated topic distribution most representative of the Cinderella retellings, the PB&J instructions, and so on.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Then, we calculated the Euclidean distance between each article in the New York Times corpus and each narrative task\rquote s centroid. This allowed us to determine the \ldblquote most similar\rdblquote  New York Times articles for each narrative task, which in turn enabled us to produce \ldblquote task-specific\rdblquote  subsets of the larger corpus.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 The end result was that we were able to produce a more topically homogeneous collection of New York Times articles to use in training per-narrative-task language models. We ended up identifying two of the narrative tasks\emdash  \ldblquote tell me about your stroke\rdblquote  and \ldblquote tell me about an important event\rdblquote \emdash  as fitting particularly well into the topic space described by the New York Times data, and focused on those two tasks for the remainder of the analysis.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 In this study, we evaluated the performance implications of using either the omnibus model or a task-specific model. In future work (see section\~{\field{\*\fldinst{\lang1024 REF BMsub_future_work \\* MERGEFORMAT }}{\fldrslt{5.1}}}), we anticipate experimentation with interpolating between the two.\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_lattice_construction_scoring}2.4{\*\bkmkend BMsub_lattice_construction_scoring}  Lattice Construction & Scoring\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 We next produced lattices representing the set of possible sentences that the subject could plausibly have been intending to produce. We did this by constructing a finite-state acceptor whose arcs represent words in the sentence. At the point in the produced sentence where our error detection system indicated that a non-word production occurred, we represent the anomaly by the union of all possible words in our lexicon (see figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sample_lattice \\* MERGEFORMAT }}{\fldrslt{2.4}}} for an example sentence lattice). \par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 We next computed weights for the sentence lattice by composing it with our language model. Then, we pruned our lattice by computing the {{\i n}}-best paths through the resulting weighted automaton in the Tropical semiring (for this analysis, {{\i n}} was 1,000). Finally, we scored each possible remaining candidate production with the final forward probability of the version of the sentence containing that candidate.\par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs22\sl240\slmult1 \sb240 \fi340  \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 
{\pict\picscalex78\picscaley78\picw1350\pich629\picwgoal6480\pichgoal3019\pngblip
89504e470d0a1a0a0000000d494844520000054600000275080600000015082aec00000006624b474400ff00ff00ffa0bda793000000097048597300002e2300002e230178a53f760000001d74455874536f6674776172650047504c2047686f737473637269707420392e313673bd3d740000200049444154789cecddbd8f
33db9a17ec7b8f0e12c16838f524c31bb1554d0202091d77849008b0094890106e0810a12da2c9b073123b83d016112761ec3fc14e21405d130212b4450404a86b40c4e337d8ac3ad57edc9f8fed2abbae4b2aedfdf4875d6d2f57adfad5bdd6fa69bfdf07000000004097fc5ed33b00000000007069825100000000a07304
a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000
a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100
000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039
825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc128000000
00d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc128
00000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e8
1cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e60140000
0000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e60
1400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000
748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080cef955d33bc0cdea37bd03000000c0cdd836bd03dc9e9ff6fb7dd3fbc06dd2b00000008053f9a9e91de0f6184a0f00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e70846
0100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080cef955d33b00000070cbb6dbed8b7ff77abdc8b22c76bb5dec76bbeaeb599645afd77bf1b365594696652f1e2bcff3c8f3fcd5e7fbeaef1445
f1a9c7deed769165d98be702806ba262140000e08c8aa288e9741a83c12006834114451111bf848cdbedb6fafa743a7df1f3f7f7f7f1eddbb758afd7311e8fe3dbb76f31180ce2eeee2e0683419465f9dd737ce677d23e8cc7e3984ea7b1dbed623a9dc6dddd5dacd7eb178f3d9fcfe3e1e121eeeeee62bbdd563ff7eddbb7
ef1e1300ae8560140000e08c2693494c2693efbedeebf562369b45bfdf7ff1f5f57a1ddbedb60a5097cb654c2693787e7e8ed96c165996c576bb8d8787871ffa9db22c633018449665b1582c62341ac56ab58a2ccbe2e1e1a1aa745dafd7d5569665cce7f3c8f3bcaa6ead57bd02c035118c0200009cd967869bcf66b31741
ea6432a986b74f269358ad5611f1cb10f9145e7ee577c6e371144511a3d1e8c5f3a7a0763e9f578f3d1c0eabef8f46a3188d46b1d96ce2e9e9e9bbe1ff00702dcc310a0000d0326f05a9fd7e3ff23c8fdd6e17ebf5ba0a323ff33b799e57c3e5c7e3f18b9f4d15a0f5b951ebe1677a1ef38b0270ed04a300000057a6d7eb7d
b778d3677ea73e87e866b339c72e0240eb194a0f00007065de5a39fe23bf63c12400108c0200005c9d146c7e667ecffaefd443d2fa90f943165602e0960946010000ae4c5a7dbebe28d2677ea71e8ca645960e4da753c12800374d300a0000d0a0143e7eb4fa73b7db455114d1eff7bffc3bf5dfdd6eb7311e8f5f0caf5f2e
97d5cf03c0adb2f8120000c099f57abdc8b22ccab2ac2a34cbb28ca228aa95dde7f379144511a3d1e8c56aefdbedf64540391e8f23cbb2582c16af3edf477e67b158c4603088b22c63b95cc67abd8e5eaf5705a4166502e0d6a91805000038b32ccb62b3d944bfdf8fed761b0f0f0f5114454c2693c8f33c86c3612c168b58
ad56df0d8f2fcb321e1e1e623a9dc6dddd5df5586f2dc0f491dfe9f57af1f8f85805b16559c66eb78b7ebf1f9bcda60a67a7d3698cc7e3eaf7a6d3694ca7d313bf420070793fedf7fba6f781dba4610100c0176db7db180c06111155a07a8edf01b8223f35bd03dc1e15a30000000040e708460100000080ce118c02000000
009d23180500006891ed761bcbe5f2c5bfb7dbed9bbff3dbdffe36fec5bff817d5bffff5bffed7f1dbdffef66cfb0800b7c0e24b9c8b860500005ff05a089a6559acd7eb6af5f8b77ef6505a8829cbb2c8f33cfafdbec599806b63f1254e4e30cab968580000f003cab28cf57a1d45515481e85b0e83cea228defc9d2ccbaa
8074381c46966527d96f8033118c72728251ce45c30200804f2a8aa21a3a7f580d9a65591560a61034cff3c8f3fccdc72ccb328aa2a81e7fb7dbc576bbadaa4e935eaf5785a4bd5eef847f15c04908463939c128e7a2610100c0072d97cb58afd7df85a1e70c2b53089baa52ebf23c8fc96412a3d1e8a4cf09f00304a39c9c
609473d1b00000e01dcbe532e6f3f98beacde170580d717faf1af4545e1bb69fe7798c46a3188d4686da034d138c72728251ce45c302008023cab28ce57219cbe5b20a44b32c8bd1681493c9a4f100b22ccb98cfe7b15c2eab80b44dfb077496609493138c722e1a160000d41c0b1cf33c8fe170d8dac0f1b0a23505a4a3d1
e862d5ac00ff8f609493138c722e1a160000fc3fd3e9f4bb40f49ae6f04c15aef5b9482793496b035de02609463939c128e7a2610100d079dbed36c6e3715571991652ba9640f4d076bb8df97c5e2d1295e779cc66b3180e870def19d00182514e4e30cab96858000074d66eb78be9741aebf53a227e19823e9bcdae36103d
b45eaf633a9dbe087c178b85e1f5c03909463939c128e7a2610100d04987c3e66f75c8799a33753e9f575fbbd5bf156805c128272718e55c342c00003aa5288a188fc7d53c9cfd7e3f66b359f47abd86f7ecbc76bb5d8cc7e317c3eb178b45f4fbfd86f70cb83182514eeef79ade010000806b379d4ee3fefe3e8aa2882ccb
62b158c466b3b9f95034e2972074b3d9c46ab58a3ccf63b7dbc5603088e9745a55cd02401ba918e55c342c00006ede6195e870388cc562d1d9a1e487c3ebf33c8fd56ad5898018383b15a39c9c8a510000802f98cfe731180caa2ad1d56a15abd5aab3a168c4ef16994aafc36eb78bfbfbfb984ea74def1a007c47c528e7a2
6101007093cab28c8787876a4e4d2bb21f5796658cc7e358afd711f1cbebd4f5e018f8212a463939c128e7a26101007073cab27c51259a5661e775cbe5b29a6fb4d7ebc566b3118e025f2118e5e404a39c8b860500c04dd9ed76f1f0f05085a25d595ce9148aa288c1601065597aed80af128c7272e618050000784751142f
569d17ec7d4eaa14edf57a55d56d9a8a00009a22180500007843bddab1d7ebc5e3e3a350f40b8e85a3cbe5b2e9dd02a0c304a3000000af582e97717f7fff627e4c8b2c7d5daab61d8d461111311e8fad580f406304a3000000472c97cb188fc71111311c0e2d1a74225996c562b1a816ad9acfe7d5eb0c009764f125ce45c3
0200e06a4da7d398cfe71111311a8d62b15834bc47b7a91e3e7b9d8177587c8993fb55d33b000000d026e3f1b89afb5258775ef521f5e935f77a03702986d2030000fc3fd3e9f4454027a43bbf7af8bc5c2eab4a5d00383743e939170d0b0080ab521fd6bd582caa6a462e633e9f570b3179fd81230ca5e7e404a39c8b8605
00c0d5288a22eeefef2322623299c46c366b788fbaa93ea47eb3d944bfdf6f788f8016118c72728251ce45c30200e02a9465197777775196650c87c358ad564def52a7a57034cbb2d86c36d1ebf59ade25a01d04a39c9c609473d1b0000068bdb22c633018445114d1ebf562b3d94496654def56e7dddfdf4751149165593c
3e3e469ee74def12d03cc1282767f1250000a0b3a6d36915c02d160ba1684ba44ad1b22ce3e1e121cab26c7a9700b8412a4639170d0b0080569b4ea7d50ae8e6b36c9ffa1407aa79815031ca19a8180500003a67bd5e57a1e862b1108ab6509a6334cbb2288a22c6e371d3bb04c08d5131cab968580000b452511431180ca2
2ccb188d46b1582c9ade25de501445dcdfdf474478bfa0db548c72728251ce45c30200a075cab28cfbfbfbd8ed76d1ebf5e2f1f1b1e95de20396cb655531ba5aad62381c36bc47400304a39c9c609473d1b00000689db4da799ee7f1f8f868ceca2b92e684cdb22c9e9e9ebc77d03d82514ece1ca3000040278cc7e36a05fa
d56a2558bb32b3d9ac5aa9de7ca3009c8260140000b879cbe53296cb6544fcb2d852afd76b788ff88a34bf687df12c00f82ac128000070d3ea2b9a4f2613f3535eb15eaf1793c9242222e6f379ec76bb86f708806b668e51ce45c30200a0150683416cb7db180e87b15aad9ade9db32acbb2135304a4b962fbfd7e6c369ba6
7707b80c738c72722a460100809bb55c2e63bbdd469665319bcd9ade9d0f4b55ae777777b1dd6e3ff43bbbdd2eeeeeeee2eeeeeecc7bd7bcc562115996c576bb35a41e802f138c02000037a92ccb984ea71111311a8d22cff386f7e863a6d3693c3c3cc472b9fcf450f1b22cabed9619520fc02908460100809b349fcfa32c
cbc8f3fcaaaa4567b35915fa7d469ee7f1f8f8184f4f4f9d184e3f994ca2dfef5ba51e802f138c02000037a7288a6a88755ac9fc9a7cb5bab5d7eb7522144d0ca907e04708460100809b9386d00f87c3e8f7fb0def0de792e7f98b21f5455134bc47005c13c12800007053ae75c1a5f7946519dbedf6ddf943dffb7e51141f
7a9c6b61483d005f25180500006ec6b52eb8f496b22ce3e1e121be7dfb1683c120be7dfb16e3f1f845b099a60e483f776c25fbf57a1df7f7f7b1dd6e63bbdd568f379d4e633a9d5ef550f434a4be288a582e974def0e005742300a0000dc8c6b5d70e92dcbe53266b359ecf7fbd86c369165592c97cb787878a87e66bbddc6
6eb78bf57afdea633c3c3cc468348ac964522df094e6e6ecf7fb573de5409ee7311a8d2222ae3ae005e0b204a30000c04db8f605975e33994caacad77ebf5f05bea9f233fdcc70383cfafbbbddae1a625eafa04d737346fcf2daf57abdb3ecffa5cc66b3c8f33c76bb5d55350c006f118c02000037a12b0b2e8d46a36ae5f9
d72a44eb76bbddd1af67595605a5b734df68c42f15b2b7f23701703e82510000e0eacde7f39b5c70e935a9baf3b5d0b32e85a811df07a02918adffcc354bf3ca966569483d00ef128c02000057ad1e82ddca824beff9ccb0f75eaf57fdfc6185e96eb78b2ccbaaf9396f81aa51003e4a300a00005cb5e9741a655946afd7eb
44b568dd4703d2b46afb7abdaeaa6bd3eb961674ba15a3d1287abd9eaa5100de2518050000aed66eb78be5721911d1a950b4288a888857175c3ad4ebf562b3d954d594dbed36f23c8fa7a7a7ab5f74e998d416e6f3f987a61b00a09b7ed5f40e0000007c55aa08bcf50597eacab28ced761bfd7effc3a16651149d997f3522
a2dfef47bfdf8fed761bf3f93c168b45d3bb04400ba918050000ae525996d59c99b7344766c4db0b264da7d3e8f57ab15aad5e7cfdb5f934cbb28c878787d86eb7d5962a4e6f597dae5155a3001cf3d37ebf6f7a1fb84d1a16000067359d4e633e9f47afd78bc7c7c7a677e7e4b6db6dacd7eb58afd7311c0e5f84a593c9e4
c5bfa7d3e98bc5867abd5ef4fbfd98cd66b1dd6e633018bcfa3ce9e76e7148fd603088ed761ba3d148d5285cbf9f9ade016e8f609473d1b0000038ab6fdfbe455996b1582c6eae62f4d41e1e1ea2288a572b27b32c8ba7a7a79b5a8429e2972904eeefef2322e2f1f1f126c35fe810c1282767283d000070755275649ee742
d177a4f9459f9e9ee2f9f9391e1f1f63b3d954db6ab58a3ccf6f72787dafd7abdac7743a6d786f00681b8b2f01000057272dba24147d5b511431180caaf948b32c3b5a35b9dbed6e76f1aac96412cbe532b6db6dec76bbc8f3bce95d02a025548c0200005725055c59960946df511445946519f3f9fc684568fade2d878579
9ec770388c88df05ea0010618e51ce47c30200e02cd2823a93c92466b359d3bbd37ac716664a7389e6791eb3d9ece6e6163d9416a0bad5b954a123cc31cac9094639170d0b008093ab2fa6f3f4f474d3958e1fb5dd6ebffbff7af8d9eff7a32ccbef2a466f75e8fc6beeeeee62b7db59ac0bae9760949333c7280000703596
cb6544fc32b7689742d1a22862bbdd5643e3d37f3fabdfef57f38cbe36dfe8ad1a8d4655f5ac6014800815a39c8f860500c049ed76bbb8bbbb8b8888c7c7c79b0ef5ea41e876bb7d3304cdf3bc0a89d36b92aa438f558ad6655916fd7e3f7abd5ef5df5b559665dcdddd455996b1d96c3a57310b3740c52827a762140000b8
0aa95af45603bced761bebf53ad6ebf57741683dc0ecf57a2fc2d08fdaed76b1dbeda2288a17816b7acefaf30c87c36ac1a25b9165590c87c3582e97b15eaf05a300a818e56c342c00004ea65eedb75aad6e26b42bcb3296cb652c97cbd8ed76d5d72f55c9f956656a5acdfd96a62da8cf51fbfcfc6c1126b82e2a463939c1
28e7a26101007032f3f93ca6d369e4791e4f4f4f4defce0f4b559aa95233e277158da3d1a8b18ad8a22862bd5ebf58c53e22aa0ad25b08a40783416cb7db984c26319bcd9ade1de0e304a39c9c609473d1b0000038995b58517cb7db55c3b8ebd5a1bd5e2f46a3510c87c3565530a67dadaf7a9f65598c46a3abae225d2e97
311e8f6f2664870e118c72728251ce45c30200e024d6eb753c3c3c449665f1fcfcdcf4ee7cda6eb78bf97c5ecd911a715d01e36b81ee68348ac964d2fafd3fe6dbb76f37372d037480609493fbbda677000000e02da962f1da2a4577bb5d8cc7e3b8bbbb7bb170d462b188e7e7e798cd6657112ae6791eb3d92c9e9e9e62b5
5a558b162d97cbb8bbbb8bf178fc2230bd06a92dd5c36a00ba47c528e7a26101007012a9baeff1f1f12a56a33f5621daeff7633299dccc4ae8dbedb6aa224dd27400d7f037ee76bbb8bbbb8b8888a7a7a7ab08a80115a39c9e8a510000a0b5d6eb75946519799eb73e147dad4274b3d9c466b3b98ac0f0a3fafd7eac56ab78
7a7a7a517d39180c623018b4be8234cff36a08bdaa5180ee128c020000ad9586d1b7791ec8b22c633a9d7622103d94e7792c168b1701e976bbbd8a21f6a94dd5ab5e01e81643e939170d0b00801fd6f661f4d3e93496cb6594651911b73764feb376bb5d4ca7d32a6c4c8b4c4d2693c8b2ace1bdfb5edbdb17f082a1f49c9c
8a510000a095da3c8cbe288ab8bfbf8ff97c5eed63172a44df93e779ac56abea7528cb32e6f3f98b6ada3651350ad06d82510000a095da3a8c7e3a9dc6fdfd7d14451159965543c9bb1c881e4a5309ac56abc8f33ccab28cf1781ce3f1b8aaae6d83f49e094601bac9507ace45c30200e0cbcab28cbbbbbb560d732e8a22c6
e37114451111bf04b68bc5a29543c4db663a9dc67c3e8f88885eaf178bc5a215ef695996f1eddbb78888d6b433e05586d273722a46010080d669db30faf97cfe5d95e86ab5128a7ed06c368bcd6613599645511431180c5a31b43ecb32c3e9013a4c300a0000b44e5b86d19765190f0f0f319d4e23e297a1d78f8f8fd50aec
7c5cbfdfafa61c68d3d0fa349c3eb53900bac3507ace45c30200e04bda32bcb92ccb180c06d5d0f9d96c1693c9a4917db9356d1a5a5f6f6f4f4f4f91e77923fb01bccb507a4e4ec5280000d02a694873afd76b2c2c2b8a22eeeeeeaaa1f38f8f8f42d1136ad3d07ac3e901ba4b300a0000b44ad3c3e897cb650c068328cb32
7abd9e4579cee4b5a1f54ded4b846014a06b0ca5e75c342c00003eade961cdf3f9fcc57ca21658ba8cfad0fad168148bc5e2a2cfdf74bb033ec4507a4e4ec5280000d01af561f4970ea7c6e371158a8e46a36aa837e7379bcdaa3074b95c5ebc72d4707a806e128c020000add1c430fab22ce3fefebe9ae372b1585cbc6291
9795a24d84a386d303748fa1f49c8b860500c0a77dfbf62dcab2bce8bc9e0f0f0fb15eaf23cbb2582c168dcd6dca2feaa1e82587d51b4e0fad67283d27a7621400006885a228a22ccbc8b2ec62a1e8783cae42d1cd6623146d81a62a47b32cabaa4653e53200b74d300a0000b4420aa35238756ee3f1b81a3e3f9bcdac3cdf
224d85a3a90d14457191e703a05982510000a0152e198cd643d1c56211a3d1e8eccfc9e734118eaa1805e816738c722e1a1600009ff2d34fbf4c1f77eef91d85a2d7e5d2738e5eaa1d029f668e514e4ec5280000d0b854a197e7f959c3a8f97c2e14bd3297ae1c55350ad01d82510000a071971846bf5c2e633a9d468450f4
da1c86a3e97d3c07f38c02748760140000685c0aa1ceb5005251142f86630b45af4f3d1c9dcfe7b15eafcff23c299c3fd7e303d01ee618e55c342c00003eec9cf33a9665197777775196650c87c358ad56277d7c2e2bcd119b65593c3e3e9e65ea856fdfbe455996f1f8f878b6b01ef834738c72722a46010080469d7b7ed1
c16010655946afd73bfbc23d9cdf6c368b5eaf176559c6c3c3c3599ec33ca300dd20180500001a75cef945a7d3691445115996c562b1882ccb4efe1c5c56fdbd2c8ae22cf38d9a6714a01b04a3000040a3ce158c2e97cb98cfe711f1cb624b8644df8e7af5ef39e61b55310ad00de618e55c342c0000de5596657cfbf62d22
229e9f9f4f56d159144535847e3299c46c363bc9e3d22ed3e934e6f3f959e61b35cf28b48e3946393915a30000406352455eafd73b59289ae69e2ccb32fafdbe50f4869d73be5155a300b74f300a00003426cde178ca61f4e3f13876bb5de4796e05fa0e58ad5667996fd43ca300b74f300a00003426854ea71aaabc5eafab
f9265360c66dcbf3fc2cf38d0a46016e9f394639170d0b008077fdf4d32f53c69d627ed1b22ce3eeeecebca21d559f6f74b3d99c246c4fedf3e9e9e9a4f397025f628e514e4ec5280000d08854899765d9492a3bc7e371946519bd5e4f28da41f5f946535bf851698a0755a300b749300a000034e294c3e897cb6535843a0d
aba67beaf38dcee7f31f7e3cc3e9016e9b6014000068c46eb78b881f0f4677bb5db5e8ce643239d97ca55c9ffa825bf3f9fc8703cd347c5e300a709b04a3000040234e55316a083d75fd7e3f86c36144fcd2367e848a5180db26180500001ab1dd6e23e2c782d1f97c5e3d8e21f4248bc5e22443ea7bbd5e64591665590a47
016e9060140000b8b8fac24b5f5dedbb2ccb2af432849eba2ccb62329944c42fe1799ab6e12b548d02dc2ec12800007071a7985f743a9d1a42cfab52585e96653507ed57a436fa23e12a00ed24180500002eee47e717dd6eb7b15c2e232284a2bc2a4dafb05eaf63bd5e7fe931548c02dc2ec128000070712964faea30fa34
847e341a45bfdf3fd97e715b7abd5e35a43e55187fd6b195e9cbb28ced761bf3f9fc87e63005a059bf6a7a07000080eef9918ad1e57219dbedf6c53c926d539665645956fdbb288aa3f3a9ee76bbd8ed761f0a77eb8b55d51ffbbde7de6eb7effe4efabda22822cff317fb99f6f1507d9fd3be6559d6bab95e279349acd7eb
d8ed76319fcf3f5c619c5e8ff4b79765197feb6ffdadf877ffeedf7df7b3bd5e4f400f7085548c02000017b5dbedaacabdcf8668f5059746a3d1972b4ecf21ad803e180ce2dbb76f5545e1dddd5ddcdfdfc7dddd5d35d7e576bb8dbbbbbbb8bbbbab7efed850ed343fe6c3c343144551fdde6030a8c2c8fa73dfdfdfbf78ee
6fdfbe558fffda3c9b6559c6783c8ee9741abbdd2ea6d369dcdddd5543cfd33e0c0683180c06319d4e5f3c777afec37d6a8b2ccbaa30f4b585985205e8bffc97ffb27abdd26b371e8fab9f3b168aa6e700e00aedf77b9bed1c1b00001cb55aadf611b1eff7fb9ffeddc964b28f887d9ee767d8b31f33994cf6bd5e6f1f11d5
dfb7d96cf6fbfd7ebf582caaaf4f2693fd6834da3f3f3fef9f9f9fabdf397c3dd2f786c3e18baf3f3e3eeeb32cdb47c47eb1587ceab91f1f1f8f3ec7643279f1f5f458e9319e9f9fabe73cfcd9f4fdd168f403afdef90d87c3ef5ee7a7a7a7fd6834daff85bff017f611b1fff9e79fabd7ea331b70114de71cb61bdc548c02
000017f5d561f4692874443b175c9acd662f86f6d7e73fad57b76eb7db582c16916559645916c3e13022be5fdc2755891e4e17d0ebf5aabf3f5579ce66b317afc9e173a7d7fa7001a2f1781c4551c468347af1f5f4bbe9f5ceb2acfa99f97cfedd5c9debf5baf543c9d3ebb3dd6ee3b7bffd6d8cc7e3b8bbbb8be57219fffb
7fffef8888f8d5af3e3fdb5cdbff6e005e27180500002e2a0d65feec30f83414bcdfef576162dbd487541f0eaf4e7fefe1d753685996651538a6037ded78000020004944415461f3f5efd7a590b22ccb582e976fee47fddff561e4bbddae0a4ac7e37135547e3018545faf0f8d9f4c26d5e31c2e38b4dbed5afb9e24799ec7
3ffec7ff382222fee93ffda7475fb79f7ffef9d3edb24dd33900f03982510000e0a2be128c6eb7db2aac6b63b5e8a9a4aad18fccd5992a158fcd4dfa9a7aa567bd7a74b3d9bcd89e9e9eaa618649bd6a74b95c568f756cceceb6298a22c6e371fcdb7ffb6fdffdb9cf2ee8251805b85e82510000e0a2be3294bebee052db56
3d3f87c3a1eac7fc6820f791e73854af544defc972b9fc6e287e5b6cb7db180c06717f7f7fb442f45059969f5ed4ab0bed11e05609460100808b49d585697ecd8fd86eb75505e567abf9aed547e6ad4cafdf5783b97af8f756856abd2234cff3a355a36dac9a4ca1e847aa6feb3e5b356a8e5180eb25180500002e26856c5f
ad166d6300770ef5d7e7b54ac7af2e6295d45fcbc3394393b4b8535d0a0dcbb28cf1787c73ef49aa1afdc8ebaa5a14e0ba09460100808b49d57b1f0dd36eb15af42395b25996557fefb1d0b22ccbd86eb7d1ebf5bebce851bfdfaf82bded761be3f1f8c5f0fae5721945517c571159af1add6eb7ad1d46dfeff7bfb46f2908
fec85cb6825180eb26180500002eeea3c3e86fa95af4338b2445fc12cc8d46a3d8ed76df85a3f3f93cb22c8bc562f1a9e73e7c0d178b45f55e2c97cbb8bbbb7b3127e76ab53afa7829b46d6b289a2c168b4f07ea2918edf7fbef0e93bff63649b7a41b4d69bb8685d3e0dc7ed5f40e000000ddf199e1dfd7562d3a9d4e5fac
f43e9fcf63bbdd46bfdf8ff97c5e5563aed7eb180c0631994c62bbddbef89de9741afd7ebfaa565c2c16d1eff763bd5ec7fdfd7df4fbfdd8ed769165593c3e3e56c1dce173a7c7397ceee57219599655dfebf57af1f8f818f3f93cd6eb75946519bbdd2e86c3614c26935703ec3ccf7fa85af59266b359e4791ee3f1f8d3bf
9bdea3d7a818a56d76bbdd8bcf72aa2e7f4bafd78b2ccbaaf6fc919b02702b7edaeff74def03b749c30200e03b777777b1dbed62b3d9bc7be19d16ce198d461fae8ce432d2fca2af5594b6d172b9fc5038daeff763b3d954ff7e6b01a7e7e7e70f573fc3b9144511ebf53ad6ebf59b55a0799e7f78d1b52ccb62381c563740
5ad2ce7f6a7a07b83d8251ce45c30200e03b3ffdf4cb75ed7bd7216945f18888a7a72743965b262d08d5f6a1f4873e128e1e06a3f5b65897e7793c3d3d9d7c1fe123d6eb7555715e9f1b382262381c469ee75515e861207a68bbdd46599651144555617a18b0d643d2068fc782514e4e30cab968580000bc501445dcdfdf7f
2850522dda2e695a837ebf1f5996c5783c8ec7c7c7a677eb4b3e128e1e5e278fc7e32a0c4e86c3e15555cc721b96cb654ca7d3176168aaee4c43e04f51dd99aa50b7dbed77f3238f46a3984c264d04a482514e4e30cab968580000bc902aef0e2bf20eed76bbb8bbbb8b08d5a26d71389c7c32997c68d5f6b67a2f1c3dbc4e
aeb7c9e4da5f03aecb7abd8ee9745a5572e679fe220c3da7346fe97abd7e11924e269337e7223e03c1282767f1250000e02252b0f65ed0794b2bd19fca6eb77bb125698195b76459f6e2754cc36adf1b5e5b57ffb95eaf77f581609a02e0b570b4288a170b2be5791ea3d1e845d5a8c569b884ed765b2de416f1cbe7390592
9792e779f59cf5fd99cfe7b15c2e63341a5dfd3181ee128c72738aa288a228aa4e637dae94ba632befa5af0100703e6ff5b776bb5d153e5dc38ae7a7b4dbedaabe6c0a3c0f83d073a887a4a97f9ce6254c168b453544f75602c1b7c2d1c36b87885faae3eac1a815e939a7dd6e17e3f1f845209a86b03779cd9a2a54b7db6d
8cc7e3d8ed76319fcf63bd5ec76c36ebdc719beb67283de772d18695e63c7a6f15be8fa80f4750a1701dd2fc371fb980a807e2692e1eef33a790da61fa7fed90364b0b2ba4b6fada4dc4248521293869d1eab4b4c067db5344c45fffeb7f3dfededffb7b47dbd3743a8df97cfeee70fb6b57bf995f0f43df9202c9c340eebd
a0f2f0b13ffa3ea5c7ae2fde722ba168ddb161f5b3d9acaac8abb7f174bdf17bbff77bf1677ff667471fcf31931f5514450c0683eaf3f9d9393dd3d0f7fae7fc709ed0e4f0c6c86787e62f97cb98cfe755bff7cc534c184acfc909463997b337ac14841e5b85ef54d2aa7ba3d14867a665de5a85f1b37abd5ef4fbfd6aa545
f8a8d40e8faddcf959e9c2493be45ccab27c71ecfc512d599d96869cab3dfdddbffb77e3effc9dbf136559c666b3b999106eb7db55e78a630b99d4a52032fd7ffdbfe7520f4ed27febf3891e4a15a5f5edda1d86a37ff4477f147ff5affe55c74c2eaede167bbd5eac56ab0fb599b7164bfaacfa624e1fa9002dcb32e6f379
350dca70388cc562718e6b68c128272718e55cced6b00ee758f988fa90f98878f38ed96bbfdf86610b5db7dd6e63b95c7ed7394d27ee7487f3f0fd4e0e3bfce94e6a5d0aa7cc69c66b5ebb2973d80e235ebf90dd6eb76fb6c3f4580dadf6c98d592e97b15c2ebf3befd5ab98ead560870ee7353c76c1e54662775ca23d4544
7cfbf62dfeeb7ffdaf57d99eeac1e25b95a0e935aa0f5b6f5bc058af664dff7fec46607df8fd29a7a74a41cfa5fae06f2dc8748e63e625e788e43aa48af9888f858b29903c36723285f08723950ea56354ea9f1e2b3c49e7f8f76ed27c35d4fd04c128a7b7dfef6db6736c27f7f4f4b41f8d46fbf825747d75ebf57afbc964
b2df6c36fbcd66f3ee636e369bfd62b1d80f87c37d96656f3e769665fbc562718e3f8f373c3d3dedfbfdfe8bf722cff3ea7dfe11cfcfcffbc562b11f8d462fdeff2ccbf693c964fffcfc7ca2bf826b77ec1894dae16ab5fae1c75fad56dfb5c388d88f4623ed902f59ad56fb3ccfbf3b47ce66b3fdd3d3d30f3df6d3d3d37e
369bed87c3e1779f09e7c9dba43dbdeee9e969bf5aadf693c964dfebf55eed43f6fbfdea9c71cdc7f5e7e7e7fd66b3d94f26937dbfdf7fb5ff9cfae48bc5e2cb7f6feafff57abdb3bf669768e3c7fab3d7d0c639bfe7e7e717ed633299bcfbf393c9e4bbeb97e170f8439fb9e4f1f1713f994cbefb4cf4fbfdfde3e3e3bbbf
9bf62bcbb21fbe5e3bd074ce61bbc1adf11db0ddec7632cfcfcfef06a2a7eab4ecf7af8713879d98530421bced5810351a8dde3d19ff88d56af5a253920252ba2b753cdbd00eaff9429acbd96c3647dbcf29ce91c7a41b4cf58ba73ccf4f7d214443b4a7e352d075181ad4fba6a3d168bf582cce7abe688bc7c7c7fd62b178
331cfe6c7f7db3d97cf7fbe7380f1e6be3fffc9ffff3b39d738fb5f15eafd7ba36cee53c3f3f579f9b8f14e2cc66b317d7aafd7effacd7a629243dec0bbff5597e7a7a7a712c38e10d80a6730edb0d6e8def80ed66b793787c7c7cb57395eea49d3328d86c36ef3e3fe771780774381c9eed22ec98c3aa016178371deb785e
f202f7f01894659976c8ab9e9f9f5f54dc3511a81f1ebbfbfdfe458fdd9c8ef6f4bd14861eeb1bde4a35e8a93c3f3fbf5945fb9190f4b082f8d4e1e86185dea5dbf8b18abfa6db38cda887a26ff533379bcd77d72797ac383e56b4f2d6f5f06181d389fad04de71cb61bdc1adf01dbcd6e3f6cb3d9bc5ab5f9de1daa533bbc
ab5bdf86c3a10ef0091d5e88f5fbfd46efa01fbef7b3d9acb17de1b2ea1db9a62b390edba19b321c3abc9178e9f364dd6195f57b177ab4cfe3e3e38b634e97dbd3f3f3f3ab61e8a986ac76c16bd325a473ec643279f1be3e3d3dbd5a98f0eb5ffffa87db80364e5ba4fee67beffb62b178d1469a9c82e1b0cabadfefbf791c
4c9ffb2ccb4ef1396b3ae7b0dde0d6f80ed86e76fb21b3d9ec6847e8d2d55a870eefead63b74eeeefeb8330eb9f82187773b47a351d3bbc419d58733b52d0cafb74337654856abd58bb9bcda7241ddd6633a6fabb7a73ccf3bd99ed250e763219e30f4c7bdf5faa6b9bbffc13ff807af06a33f1a8e6ae3b445fd9af7ad1bf0
87d7216d39fe2c168beab3d4ebf55efd2cd5fbd627a8fa6e3ae7b0dde0d6f80ed86e76fbb2d7e6136d4b3871d8697177f734ea15c26d7d2deb9d974b2c02c0e51d4e16dfc661ebf58a01376568fb71e97014801b4bed766dede9d4d5f3af8575a79ccb9e97ea21e97b8ba09e221ced7a1ba73d56abd5bbd7b99f5d90a9091f
5d68e9e9e9a9fab91fec0b349d73d86e706b7c076c37bb7dc9b150b48de1c46b0b42b529d09b4c26af6e6d734d41cf6195419bf7b549695eb1b65d70bca5fedebe75d7bb0d0e3ba16dde57cee79a2ad9ebc344fbfd7ed3bbc311d7da9e86c3e10f3dd6b1857084a1cd59ad56fbbff137fec659c2d16b6de36ddcd7c562512d
56dbd645a31e1f1fabe91bda76dea9f7e35e7b7f9f9f9fabe352d343e7df7338daeab57dad2fa8f603d7a44de71cb61bdc1adf01dbcd6e9f560fc7ea9dd2365ff01faece97c2b2368441a9a35fdfb736ae8cfaf8f8d8caa1216fa9cf4bd5c66a83364877b7db18c41f53efa0be374f525bd4abd7db72dce172ea554f6d1951
f19efa90bb365ee8775917dbd3b1856fd2e23bc2d0e63c3f3fef7ffdeb5f9fbc72b4de67bfa636dec67074341abdb891d0c6603405b76dadb4ac5f471c530f1adb34ddc35b0e0b875e6b17f576fdc5b6d374ce61bbc1adf11db0ddecf629f5bb476d1ede72ccb140b74d77255340d5a67d4a9e9f9fab0b921fadf8b8b4fa70
906bdbf74b782b186ddbe7ba7e47feb50e6a5b5df3bef3751f197ed756f57d6f73f54b9774ad3da55595eb81685ad9b96de7a773787e7e6ef5df79ace8e047c3d16b3eeed4af33dab4ef2708b72ea28d37ead38da82ccb5efd2c7e7441a636aaeffb6b3799d2cf7cb1efda74ce61bbc1adf11db0ddecf661f54aadb6555d7e
d4b170b42d7776db1a8c9e7812ee46d4ab5ddbd4e16a83343fd6b16930fafd7eab3ad1e933726dc79de423c3b1b81db7f07e7f74b109ceef16da533d487bab3d3d3e3e7e370d52afd76b55d854b7d96c4e3a5439ad223d994cf6799eb77668eecf3ffffca560f4b570f4d6da785b42b27a514b9b8fe36d0b46eb4521af7dfe
3e7a4c6bab8f5ce37de4757843d33987ed06b7c677c076b3db871cce4772ad77c6f6fbe3f3a3b6a1c3d9d660f4237713af415befe4372d75ea0e3fcbe97d6f4b47ef9aefc8d75d73350c1f774b15c2b7f2d9bb665d694f29103c1cd9d396f3d03193c9e445fff847f735ddc84d372bd3bfdbd6373c5668f023e168bd8db7ed
6ffdac74c3b92dfde66b0b46dbf2fea7fe719ee747bf7f2bfdb98f8cac7befb57843d33987ed06b7c677c076b3db871c1b2ed3b685963ee358c8db74055adb3a04fbfded550ba576dc96ce6adde3e3e37eb3d9bcdb0ed3cfbdb7ff878ff3da63a70e735dfde6c16c36fbd0f39dd3ad743e93367eae0edbc6e3e3e3d1f7fce9
e9e9c3fbbcd96cde6cd3e9b1ea5bfd39eb5f7fad8aa1e9b6f99a6baf6eae3bac28698b1f6db3c7dadfe1cfa5af351d08df7a7b5aad56df2da8341a8d5af9d93ee694c1530ad5ea8ff3f4f4f4e27d6f431b380cb07f645b2c1637dfc69bf45afb6ca2cf79f83bf5c76ed375503d2c3c76bd7bc255db5be1bd9175f51b179fac
e86d3ae7b0dde0d6f80ed86e767b57fde05f0f4bae59fd005fef8437a94d1d82fdfee5d0896b7fbfebd2ebdcf4fb9da46a93c964b29fcd66fb2ccbf6c3e1f0bb0e651a52977e2ecff37d9ee72f3a6c6955cfd421df6c36d563bed6e1490b031d3e469b82d12f76c65a2d5dfc36f9794fef75fa4ca4f6523f36a6d77cb3d9bc
f8fa6bd583699194e170b89fcd66d58229c7aabe1e1f1f5fdca41a0e872f7e26b5c3e170f8a2fda5450346a3d17eb158ec87c3e1779f8526d52f429b0ed44ee50787d29dcc29dbec61fb4bc7e1bad4069b3c07de7a7bfa2b7fe5afbc788fae7141a55305a3cfcfcf1f7a9c3654d1ae56ab7dbfdfdff7fbfdefae117e64bb95
365ebf766afa86ee61fb3c5cc8ec58dfea5c7dcefdfe77fd843ccfab7ec26834aa1ea70dd741a940e0b57df9c179375be9bdf9545395f8278b899ace396c37b835be03b69bddde7538f4bc0d27ac5338b69054939df1b605a33f306ca2d5ea77459bbeb0e8f7fbdfcde9933a1ef5e12ce9bda87730d3055496652f7eae7ea1
5fbf78aa0f7b3bbcf038ecb4b769d8d54726bebf464f4f4f8dbfc61f6d2fe9a2252d04f2dac54bfadee150acfabc71876dadfe3a1c0b9f5e7b8ec38badfa8559d3da76f3e554eae784a63e8be768b3a96dbe7601dff4fb78ebede9cffdb93f5705a2d77a8c3fd539f3238fd3b6696eea5205600ac82693c97e32997c3840bd
a59b9ffb7d7bfad1f57655bf01f95abff09c7dce743c3eecfbd6fbe64d5f07bdd73f6b43ffed5cde2b44f842a142d33987ed06b7c677c076b3db9bea07ff5b3c091c0e056af2c2a34dc1e87b4348aedd7b77822f21753c0f3f4fe93357ef7ca6b671181c1dfb4cd63bc087ef5deac0bed7a1694b30da962ab573496da0c98a
83fa340587ede5b5390deb61755d6aa7c72a7eea95068737a052f5ece1f3a46a94633f7bf818e9b56cfaf8995ecf364ed7710a6da8de3e659bddef5f4e157418cc2d168b46cf815facd0b90af5913b7ff4477fd4f4eefc908f9e33df9afe238589f51b45878fd5b6696ebeaa1ea0fe937ff24ff611b1ff833ff8839b6ce36d
1879f556fb3c764c3f679f331d6f8f1d57db52319a3e67afcdb7995e9fd7be7fcdeaefe76bc7a9d7cea5af683ae7b0dde0f67b010d984ea72ffeddeff7a3dfef37b437a7379bcd5efc7bb95cc676bb6d686fda633e9f475996d1eff763381c36bd3b2737994c222262bbdd36f27eef76bb98cfe71111df7d9ef23c8fcd6613
8f8f8fd5d7168b45ac56ab188d46471fefb5bf21cbb2a3ffdeed765fdef74b4aed30cff357fff66b36994c22cbb2288a2296cb6523fb506f2387ed25cff3a35feff57a11115196659465191111455154ed307dbf2ebd7f65597ef7b7a6634c5114511445f5f5f57afde27ddfed76b15eaf2322623c1ec76030a8b6f4f5a68f
dfe99c391a8daad7ef96a463e772b9acdefb4b3b559b4dd2e73022aae372b2dbed1a3d07a6fd198d46dffd4dd72ecbb2aa3dfd9b7ff36f1a6b4f975096658cc7e3984ea7b1dbed623a9dc6dddd5d75dcfa88a2286ee698926559753df1effffdbf8f88887ff6cffed94db6f1749d91fa336d93da54bd5f78ae3e675996d531
edd871b52def7ffafb8eed63fdbae1f01af216d4aff30fcf87e9fb799e4759969f3a7ec1290946b9b8a228be3be82d168b86f6e63c7abdde7727fea6028ab6d8ed76d56b902e5a6e4d9ee7d5df361e8f2ffefcef8537a9e391e4791ec3e130b22cab2eaa7e64bfdbd8393f546f87b7d8f98cf8e522201d7f8e7540af410a32
3f1248a6ce763dfc8c88aa6d474475ce496db47ea1543f1f6d369b17dbd3d3537527b929cbe53276bbdd8bc0e7d68c46a3e8f57a2f2e70afcd61fbab7f0eeb816fd33790bad29ed245f6b5b6a7f794651983c120b22c8bc56211a3d12856ab556459160f0f0fd5b1b3dfefbfb8a9d4ebf55edc38edf57a47bf7fcd61e97c3e
d7c65ba2de2f3c579ff31a82b4a228aa36792c18addfacbae6cfde5bea37408f9d07d3ebd2f48d68ba4b30cac51d9ec06ef52470d8195bafd757111c9d4b0aa36ead3af850aa12daed76df5d289fdb572eb8b7db6d0c0683984ea7311a8d6eee26c5a1f439bcd5aae5643299449ee72faa21afd1478e996f9d3f5230955e83
e572f9dd4dabb61f97eb3794da52f9720ee946c52ddd44ac5734a70bdf636df092ea37866eb93da573d92db5a7baf1781c45517cd796deaacaea8a74bcbff5369eae33aee91c7f8e3e67eafbb6f95a32bd47c7fa9df59131b77ac33ee2976353fd66e1b1ef470846698e60948b3b168cdea263c374afa9f3726ae96fbfd5f7
3ba9df0dbef4fb5daffaf848483a9d4e63301844bfdf8fd56ad5ea4ee5a9bcd539bd25f57678cd9dcc8fdc444917bec786daa7d72005c4690a85bafabfdf7aad9aa8f4abdf60b9f563e72d0ea5abf703ea55a34d1d6bebede9d68f81fd7e3fb22c8bb22c2f7e93f2dcae61fa8fa6b4a98d9fbbdda5a9309ab811ff15e7ea73
5ec3744ee97379ac4f531f627fcb417ec4effefe63e7f874ccbe96f6cced118c7251bbddeec5892bcff3a317b3a75614454ca7d3984ea717bde03afcdbbadc514deffba5ab45cbb2bcf8ebfed689ff9cea9dccd786272d97cb6acedb5451d2c450b3268281fa05f2a5dae17abd8ee9741af3f9fce21dbd5bb8fb5e3f86be56
f9955ed763e792fa30d1f97c7ef47dafb7c5d7aaacd21c7e9756bf98bac405539aa7b8e9367b4b1745e9f89ae6836cf20654fdc6501317e06559c6743abdd831a9a99b94e7d6f6e93f9ad4441b4fd717f5ede1e1e122d5cad7d2c6cfd9e7fc483fa149ef5d03bd159a5e425114319fcf2f325f6d7d2a8563e7f96b69cfdc26
c128177578a03bf7dddc3407d3783c8e5eaf1793c9248aa288bbbbbb8b5c781dfe7dd71c50fc88263aaae902eceeeeeee243ca52e7e6f046c0b9d5e70eab774293f57a5d2d3c93da625377a79b18be9cda61afd73b7b38918e330f0f0f55d0747f7f7fb1634f44fbefbe7fa4edd5e7883bf6394e373e7abddeabe793f4f534
85c2a1fa1c7cdbed36c6e3f18bf6b95c2ea3288a462e5a2e15e4ef76bb180c06d5dc8429d0bfbfbf8fc16070b1cf6b5337953eea2bc7cb7ad5e876bb6db4f2f7ad85cc2e211d0f2fd5176a7b7bfaaab64fffd1a44bb7f1e57259854af5ed7091bf73697b1b4fc7cc73f639eb370e5feb27443477dc7beb1aa8a90ae7fa35d2
7abd8e7ebf7fb1e97adeab1a7ded7b706e82512eead2c1e8c3c343144511abd5aa3a21cd66b3e8f57a31180cce1e5a1d4eb2ddc410c174c26db2237de9bba1f540b489bfbbc9e1f4abd5aaeafc4da7d3f8f6ed5b0c0683b8bfbf8ff1785ccd5f94de8b54c594c2907aa5696aafef7d4e521b7b2f6cac775e53d56a5a6dfb12
de5a11f4948aa2a88e2f8721ec6eb78b8787878bb5cb36de7dff6c483b9bcd62341a55d58c75f3f9bc5a7ce435e9e2f4ad2a95c562f1a26ddedddd559f9be57219abd5ea53fb7c0af5f3c539db6cba405a2c16f1f8f858559da5855c8edd643997f7aa499af2a3fb92da5e93a1687df44413438c2f198826f5a934dad49e7e
549ba7ff6852136d3c854a87db7038bc4810d7d48df888b7af2bd2bea4f3eab9fb9c9bcda63a77a41b7ce946677abcf97cfe62ba894ba92f8476e8d2a342d273a69bf48f8f8fd575f1a5bc359aa9c9f60cd5700b9bedc4db779e9f9ff711516d59961dfbb193592c16fb88d88f46a3efbef7f8f8f8eaf7ceb51f69bbc473ee
f7fbfd6432d9f77abd17cf9de7f97e381c7ee8f7178bc57e369bed9f9e9e7e683feaeffb8f3ed6473d3e3eeef7fb7df5f7f7fbfd8b3c6f5d7adf7bbddec59ffbf9f9793f994cf6799e579fb5d168f4ddeb3f9bcdaa9fc9f37c3f9bcdaadf4dbf37994c5e3c56fa9b2693c97eb3d9ecfbfdfe8b3696befe9ad56ab5cfb26c1f
11fbe170f86e9b58ad56276987fbfdfe62edb0dfefef87c3e1fef9f9b9fada66b379f1799ccd6667dd8764b55a55efefa51cb6977ebfff6a7be9f7fbfbcd66f36a1b3bfc5b86c361f5bde17078b45d1ff391e3eed3d3d37e341a55ed33cff3fd643279f13e7ec4e3e3e37e329954c7a1afbad431e4adbf311d0b7ee92e5ec6
7038ac8e259772ae365bd7ebf5bed4264e750c6cf29cb4d96c5ef4852ef9dea6f674a963ee296d369bea35ab9f57eb5f7fad7f533f17bff638c71eef52fdb473b8741bdf6c36fbd56a7591e77a4b136d7c329954e7cafaf9f2ad63e6b9fb9c8f8f8fd56b919e63b3d9547d85c562f1a9f3f96c36fbf4ef1c935ea763c7ff4b
bf77e9b5fee8b5e039bc775d98dee3b7ae25f6cde71cb61bdc1adf01dbcd6edfa977bc2e1110a603eb6b9d9674a2fad113de7b9e9e9ebeeb205c83fa3e0f87c32f770ed2fbdec4c5586a034dbce6f5f79dafab77bc7bbdde970382d40ecf1d103e3d3dbddad6eb6de252c140bd03ca65d42fdcd2c5df57da6cba8039775b79
6bdf52b07eee1b997529dcb89673e5473c3f3f7ff942f454c7c04bb5a74329f8d8eff7173ffeedf7d7dd9ede0a34eb37da46a3d18bfed962b178f1f77e2618fdd11b3a4dba741bbf54a1c37b521b6f32ecba3587d7acc3e1f0cb21f85b7db04bde9098cd6655bfe4dcd7beef792bfc1c8d461f098b9bce396c37b8194acfc5
1c0e633ae79081dd6ef7ee3c43f539e5ce29cff3177feb350ee74ac35dbe7dfbf6e909e5df5a18e5961d0e9fe66bea43b5d2226a69eecefa2acf1f7d9c73cf2d5a9665355dc1a14b2d3657976559f53777758ee326ed76bbaacddedfdfc77c3efff0f1e0a35354fca8b71e3fedc32517684bfb734bf328a6e1b65f71aa6360
53e7e2f97cfeea31f1129a5cecea9c3e33fdc77b6da4e9696e4ee5926d3c0dd54e0bd535797ebdc56366dbacd7eb787878882ccb623c1e7f7838fe47cfe3e73e4ed53fd3f5634753deba064ffba63d736982512ee6f00077cef926ebe1e37b279b4b0495f54edab51fe85348fad1ce41fa7b9b3e0937a13e570ea7f5d9b0fe
52174cf505b08e499f834bcef177abc1c0b5f96ca875a930ff35cbe53296cb65cc66b38b06a3e9337a8d3711937411badd6ea3288a582e97279f5ff4b3c7c026cec5f3f9bcd17955232e7713fcd4d2cae6f57fd7c3ca5eaf178f8f8f311a8d22cbb228cb3276bb5df4fbfd6abec5f47bf5791c0f1f27496149fadc5fea7d4b
f3829ea29f74c9369e6e72a5c5150783417cfbf62da6d3e9c5fbf96e7e5ece9ffee99fc672b9ac42d2e974fae6b9eaadf3f825170a4bf384bfd7476d83f45a5d731f80eb2418e5620e3b3de7ecb87ce4609a9eff1207dec3bff5163a2f1fed1c5caaeaa9cd04a3e7f591b0be0d3724cab28ca228a2d7eb5db46aeb5a83815b
f69150aba90abfdd6e17e3f138c6e371f47abd8b2fd4533f5f5eebb133ad4c9d2af8ce7d21fa9163e0a5dbd37abd8e3ccf1b3ff7d7db531bce031f359bcde2f9f9b91ae2971649a9cbf33c168b45f5734f4f4f319bcd5efccd1f799c885f6ed6a59f5bad56177bdfd2e72455d5bf1734bd25fdde25829f5eaf17a3d1e8c5eb
549665cce7f3b8bbbbbb685b6bfa33d6557ffaa77f1af3f93ceeefefe3eeeeee68db4dfdae63efd1a582fcfa28ca885f6e8e2c97cbaa0f92aacc2fe9ad1ba0da334d118c7231879d84a687565ff2c07beb07f98f740e6efd353826b5f16bbdb8bf368761fd783caeda617a0f9abc533e9fcfa32ccb375750a77b8e855af5f3
e5252bfc527559ba48da6eb771777777f18ba66bafb6af9fef7abddec58692bf760cacbf8e97684f6915f84b87eaafb9852ae42e288aa2ea4ba6f6fbd1e9222e7dac98cd66b1582ce2e9e9e9bb40ba2ccb180c06170d47dd006d56aa1ebebfbf3f3a6dceb1e3eea56e56d58f7bc3e13066b3598c46a3aafd46447533f452d2
eb71ec73ab2dd3496a73110000200049444154945f35bd03700ee980dbd6e1db7ff2277fd2f42e9c4dea1ccce7f3e8f57a2e4422e2bffdb7ffe6047f612920582e9791e779fcd99ffd59a3fb5396652c97cb582c1617bf29949e6fb3d9b47e08d52d787e7efed2efd5dbeceffffeef4744c45ffb6b7fed94bbf6ae14e0a5ca
a734fc6e3a9d46bfdfbff80dae6b3d570e87c3f8c33ffcc3f8fddffffdf8cd6f7ed3c8f1bfde9efebfffefff8b8888bffdb7fff6459e7b3e9fb7ea06505bfb82bc2eb5df88a8aad7fbfd7e0c87c3a3e7d0266f7ee6791e93c92446a3510c0683288aa29a42e352d390a4367eadc7ccb6f991d731bdffd3e934fee25ffc8b27
dcabafef4f72d81eb32c8bc56251558d0e87c38b7c86debaf9e9784d5304a3dca4d4697a2b804877729ba85cbde47c6d4d128afee28ffff88fe38ffff88f9bde8dce6a43d5d96030a8eed25f5afd826930185cfcf9f9bcfffb7fff6f4444fcf7fffedf1b79fe2ccbaa0aa834675e9a6ff492ba72ae3cb7fff13ffe474444fc
e7fffc9fcffe5cd3e9d4fbc6c9a5b0693e9f479ee7d1eff7abad2d414a3d648af8a5e2edd29f059fbd76f99ffff37f46c42f05124d79eff391a6774a61be1be8749560949b944e026f5569341996fce637bf896fdfbe35f6fc1fa1c2f1747efef9e7f8cb7ff92f37bd1b57e954edf00ffee00fe2fffc9fff7392c7faacf178
1ca3d1a8f14548be7dfb16bff9cd6f1add872ef8933ff9932f578d1efac33ffcc3933cce574d26936a0a88265cc3b9f2dc4e792efe4b7fe92f9decb15e53af34fec8cf4c26934657ada7595f294ed8ed76553574c42fd5673ffffcf389f7ec6b52656b537d68c7ccd3787e7e3e69f56d9395a3e933f6d6888f3ccfa3288aab
9a87194e4d30ca4deaf57a2f56e93c76326872d8cd7c3e6ffd1db99f7efae9cbbf9b16ec180e87f1f0f0d0f9cad17ff48ffe910bbf2ffa917698e7790c87c3188d46311e8f1bb9504943009b0c45d3dffd0fffe13f6cd5f0d65b35180cbedcd6529bfd9b7ff36fc6dffffb7f3ffed37ffa4f27debbcfebf57ab1dd6e1ba9ca
ba8673e5b99de21898dad37ff92fffe5847b76dc5bef577d2192d42fbbe4f40c8715f3a9af986459f6ddfe1cfe4cd2f576792affeb7ffdaf1f7e8cfaf1f63ffc87fff0c38ff7a3d231b38911698e99a7b1dd6e7f68844d1a92fe1fffe37f8c7ff5affe55fcf93fffe74fb8779f938e696f15045dfa789cae0bdb52ed0d1182
511af45a60792ac3e13096cb65acd7eba3434bd2f35fa203d1853b70799ec768348ae170f8e27dad4f46df35975a7192df4941c0e13c64e93d288ae262170dd3e9f4d55034cde178c9c05c3b6ca75ffffad7f1f0f070b1b9bd3e2b1dc72eb9908e8ba6af7bed18187199f3f066b379f57b29e44d0b805cca6b372ace71d3f6
b52035c9f3fc43edba2dc7828f5491a52284b7be7fa91be44d8d0ca94bafc5256f88beb5fa3997512f0a49efc3743a7df5e7d3cf9cfbb391ae75b7db6d2c97cba3ed32b5d94b85f96f4d67a72dd314c1281793eea026e70e4667b359acd7eba3279cf57a1d1197bbd03bec30367117f91cdeba004bd2fbdea6156a2fe5d21d
8dae4ac1d268347af5b54ec79a4b05f46925dd3ccfbfbb284fc3002f75d174a9954ff9b8d466d36222c7e4791ebbdd2eb6dbed594392a2288e56ca45fc6e75f1d96c76d18b9426e700bf461f09d7537b2a8aa2b3afeb7ebfaffeff5858772c043cd687dced76af0681a70a39de9b8e80df49c7d1b412f839db786a37f5aae7
badd6e5715645cea98596fb3c2a4cb7aad282449edf0d871e192efd56c368bc16010ebf5fa68df338d0ab9d475da5be1676acfda32972618a531e7aedccab22c369b4d7522a81fec97cb65f47abd8b552c1c76a0afb90ae62321545ba4d7bda9d75bd5d3f97c2458aafbc850a253592e97311e8fabff7fcda53aa02a97db23
05571f09c5539075ee303f2d14d2eff763b55abda8f27f7878f8ffdbbb7f1ee7b5bc0ee0bf054403e25edf86f692296857783a4483320d051599979054b42442a24fde005252d02225d5d689f615c42b3aaa58945463961e0dc5b3f67a329999cc3c499cd89f8f74b4779ff977929c38f6d7bf734ecce773954f57e82bc7c0
4b8ca76bf3d6784a92e4d539e8f79e931e531979cc321bd7f43abd75d364df4795b26f7d3dcbb2ea18f41987ce4557abd5d99fbbc562515501eeaf8f9be7798c46a3984ea717dd04c9cdcfcb3aa628a4f4deacb9f27d7589659ed234adae89f76fcc973761d6ebf5c5cf13df3a264418cf5c9e60948be9f7fb2fee805fe2a4
affc2098cd66b15aadaac5a5d334bdd849cbfe14a36b991ef5199fbd00ab7bef6ee9b94c2693d86c36d5f3be5aad62341a553b2d5f8aaaa7d3fb4cb05477a96034cbb22a147dcf6030b8d809a893cc669563f6b3aff9a5aaedc7e371ac56abd86c36717f7f5fedf49ce7792c97cb8b0794aa45def7d5f154bf08bfc5f390af
bae4783a14b6eeebd2737f8ccf7e2ef57abd188fc707c7ff25c6f870388c2ccb22cbb2eadaa2ac16ccf33ce6f37963c74c373fcfe7c71f7f8cd1687454185a578ec38f2a468ba238fbeb97a669ec76bb984c26f1f8f818bd5e2f8aa288a22862bd5e5ff41cd17929d74830cac5ec9f28ac56ab8b8454699ac672b93cfbdf79
cbfe9dc05b3971292fc4bf1242d55df28e68e91a363a2a976b7071ff7dc6e371e479fea520a0ae1ed09ff304344dd317d3359b56beef9224b99963cfadab1f3bdf9a5e778cf2f53a77983f9d4eafe2985972c1f4d2a98e8197ac9a7f4b13c7c6f218683cddb672baf27b81e725c67892248d5e531c628c9f5eb95e6879b3e3
1437270f2d2197a6696459f6e614f7534b92e42a36e12c3fe70f9d1f955f7313898b7b7e7ed6b473b4837abdde7344546db7dbbdf5adad311c0e5f3ce6f97cde74972eae7cdd97cb65d35db998f2751f8fc74d7785df49d3b473efc1f178fc1c11cfc3e1b0e9aef049bbddaefadc787a7a6aba3b17d3c5cf8b4be8ea784a92
e439229ed7eb75d35de10df573e47aebf57acfe3f1f8e86b85ae8ff1ed76db745738a0dfefbff999569ea30d0683067ad68ce57259bdbf0f39723c379d73682d6c7f7091f4157e67ff8e5b5955d766fb8fb16b1b1045fcfe315fb26ab46997dee08b8f75791cbaf37e7b7abdde8bb5f3ba20cbb2c8f3fca29b40744557c753
3943c031f07694eb1def76bb4f6dfc56df10a92b9ff39bcda61ae32a46af53f9ba1c1a935d3c2f2d1feba1cf78e399260946b9a8ae05a3e501bef4d1e2f46d55beee6d7fbd4b3ed8af537d1c5ecbc616e754864c1102fa5b5586395db9687243e9bcde5befae8d8ca7dbd0eff7234992188fc7b1dbed62bd5e7ff935eb5ad0
f45ec8c47578ef1a284dd36aadcf2e5d23451c5efac178a64982512e6a3f18ac5fb8b7d1fe8959570ff4e5eb5e1445274e567db05fa7ae55931887b7afab17f96e289d47d76e52aa98bf0debf53a9e9e9e3e551dfa16639c6bf3d13550973ee73f9a15623cd324c12817b77f205c2c160df5e4bc8aa278f5d8ba1c5074e983
df07fbf5320eb9255daa26c9f3bcaa64ecf267e539756d3c9537de1d03bba34b637cb3d9587ae446bc77eed9a59921ef55f15b4a87a60946b9b8fd13d4c562d1ca69adb3d9ecd534fa2eef505e7ec8cd66b35657092f160b1fec57ac7c4d168b45aba793968fcf38bc7de5eb37994c1aeec979958fef7b765ee763f5cfe236
1b8d4611f16d37f35b1f4f6d3c473ea7f23aa3ad8517a5f23dec33fefa9563f25058dfeff7a3d7eb459ee7adfe9ccff3bc7a4fbeb5be68841b5934a8e9dd9fb4d6b677edef4edfb69dbb9f9e9eaa5df5a2c3bbd1ef2b77666ceb0ed9f5d77d3a9d36dd1dde301c0e9f23e2b9dfef37dd95b3298fb16d3bb67651fdb8d2d6cf
91f57a5d7d561ebb03355f633cdd96dd6ef79c24c99b3b387fd67c3e7f1e0e87cf49923cafd7eb93fcce6b638c738ddedb6d7d3e9f3f47c4739224cf4f4f4f0df4eefc3e3af74ed3f433efd9a6730ead85adf10e68ad6defaa7fa0b7f183bd3cf8972d4dd3a6bb7415eaaffba113835b371e8f9f23e26417309cc76eb7abc6
611b2f0ca7d369eb4fb0bba6edc796b6df34bb36c6d3ed283faf4e713c1f0e872f0a13daf8f95732c6b93683c1e0dd1bd66dbea1fdd17977fdeb471ee79ace39b416b6c63ba0b5b67da8fc502f5b5b3edceb07f72e9c7c7e565babf5ba50a1d026e5386cdb4d0b55cbedf4f4f4d4da8ba6e57259053f6dba417acdeac709e3
e9fa6db7db93dde42a2bd33e7b6e7a6b37d9dafc59d885eac236faa8cab7cd55c0e535ff603078f7eb9fc8029ace39b416b6c63ba0b5b67de850d5681b02c4fdc0b76d01e0f76a6bb55e5b03dfb66a6b90ddf62a992e6bebc5705b03df6b673c7553fddcfb33e760fd7effe6ced9da38c6db7c93ac0b3e0a00db58097ca640
b8e99c436b616bbc035a6bdb51f6a79c274972d353acf71f4f5ba78c7faf32bc694b45c7572b3068567d1cb6e17d5a3fb96c53d8cbef9517c46db901537e66b629b8b825c653f77c25182d9fd75b3cbf31c6b9261f2d29d6b6f3b87a11c289c3e0a6730ead85adf10e68ad6d47291795df5f8ff3163fecebe158d9dccd3dec
e9e9a95a64fb565fefd276bbfdf0439feb558ec35eaf671c72f5daf43a976be146c4f372b96cba3b9d643c5d8ffae7cf6eb77bf57974cce7d376bb7d5eafd7ef7eef5bc1e85b3f57bfe13f9d4e9fd7ebf54dddd0fed5af7ef5fc277ff227ad3827af8ff15b0ca9f9e6a31966e54dfb5b2fae39e65aef3baaba9bce39b416b6
c63ba0b5b61dad5c0fea96a79f6fb7db578fa16d6b179e5a3d14bfd50bb2fa9dd05b1bb37c539f9676abaf619b6e34f0b1fa4db85bad28a987336d5bffefd6b4613ced9f470e06839b380e6eb7dbe7e974fa3c180caa5de2eba1c8af7ffdebeaebef8561cbe5f2394dd3e7e9745afd7cbfdf7f1e8fc7cfe3f1f8c57b6c3f18
1d8fc72f0a14eae161d9bf5b0a46cb3eef6f34d5a631ee9879db8e5952ac7ccfdff2ccba7a75f35b01ef772c0bd174cea1b5b035de01adb5ed53ea275e65bb95b0ac5e7151b65baf3ebb94fa09faadddc91746b5c7ad574d95d3904cadeb8e7a78726b9543b7fe7e6ba35bae50aa8fa7bff99bbf79711e76edef8df1785c9d
479461e67c3eaffeed1ffff11f5f546c1e7a3c65b05d0ffcf68f0ff5d7b47ede35180caadf590fc8dffafe6b7c3ecb70b7dfef3ffff8e38fafae25caf6f3cf3fb7628c3b66b643f91e7dab88e6d6af318ea96e2ebfe78be7ae4de71c5a0b5be31dd05adb3eedd0fa9cc3e1f0aa3f0cd6ebf5ab50b42deb155eca2d56ab3c3d
3d1d752794db511f87b714d21b87dd758baffd76bbbde98bbd36ab5728ddea787a7efe765e56af141c8fc7573dce0e2d01f0f4f4545589bd174cbe5579f6f4f4f46675e17bbfef50f5d63505a3bbddee79b95cbe0a943f6a65b1c2ad8ef1f23ac34cb4f63866edcdfaccba7ebf7fd5c7b1bafaf9f45bd5cdf599965fbcf66b
3ae7d05ad81aef80d6daf625874e74d234bdca690487d614bda570ef9ad443f16bbf1bbedbed5e8cd3a62f14389d7a95cdb5df94a9571338ee74d3ad8d81fa8d44d5cdd7a74de3e9e9e9e9c5f1bcd7eb5dedbaa31f058fef7dfdb321e7473f53ce3e180c0647f7ef9c76bbddbbd3e28f693ffef8631582d6c7789224573fc6
97cbe58b50d431b35d8e290ca90788699a5e7da07fccf55c3df0ad1f6b3ea9e99c436b616bbc035a6bdb97ec9f985f6b15e6a1ead65bb890b866f58b986bbd335abf735fae0746bbd44f54aff54264bbdd56178949925ced053fe757af82bae66ae77a55dcb5beaf68df78daaf1ebdc6b547bf2718ad8726fb9f0365c8f999
8ad1f267eaeb6d37198cbe3735fed8b67f5efef4f4543dce368c716edb31cbe2dcc2b5c7b1efab132e11d074cea1b5b035de01adb5edcbf64fccebade92951ebf5facde05638f1fde6f379f5e1dfebf5ae2a0cdf0fccaeb18a99d3d8af44bab67178adef119a53bfb8bab6f067bf82e49afac6616d1a4ffbd5a349925cd5e6
35df138c3e3fff7ea6d57ee555afd73b58997d4bc1e857ab448f093d6f698cd36ef56571debab6b8e68afefa92261f55621ff3588fd474cea1b5b035de01adb5edbbd54f5aeaadd7eb5dfc0361b7dbbd59252a9c38adfd6ab8a6c3f0dd6ef722a8bfb61368cea37ea2770d3765f68f41d75a554d73ea376f9af89cdcb75fad
774d61141f6bdb78dabfb19da6e955545e7d6f305aaf262b778d2f779a3f746e7a4bc168fd6f7fb6d51fc35bae6d8c2f974bc7cc0e3ab68ab2bebf4139c69b2cd2286f3a1d5b4870e24d239bce39b416b6c63ba0b5b69d44bd3aea502079ee93b4fd4a8343275ec289d3db9f92d14485c7a130fc5aa75c711efbd5eb4d04f5
878e41c6216fa9df586a2afc59afd7af8edf6654dca6368ea7e974fae2bc723018341a2e7c6f30fafcfced751a8fc7cfd3e9f4793c1e3fcfe7f3779717f86a30dac4f3f45651c27bede79f7f3efa73ba1e2cb7658c737bea9b317d34c57cff9c70381c5efcbdb97f7dfed1f5f01936da6d3ae7d05ad81aef80d6da7632fb27
e6fb2d4dd3e7f1787cb2aacda7a7a7e7f97cfe3c180cde0c65851397319fcf5fbcf697b8a3bf7f07f41aeecad2acfd4aa326c7e135543871dd9a1a3b6fdd4c72f3f0b6b5713ced575e35393be51415a39f393ff99ecd979a981df5f4f4f4a9b5467ff8e1874ff7b31ce37ff6677ff6628c9ffbf1eecf48ba86595234a71ed2
7fb4d1d2fed8b9d4e7ed7e55f331e7c3675a1aa2e99c436b616bbc035a6bdbc9ed8764875aafd77b1e8fc79fbed35aee7cf9d6daa64ddf99ebbafd3b9349923c0f87c393dd51dfed7655185e7fad0551d4ed1f83eae3f05417eb87c6e125aae3699f43d5c6e567e4a92ef8cb4ab5fdb5b77d4eb64f93e329229e47a3d149fe
c6fedfab57ea35319dfaa3e073b95cbef9f5a7a7a7aacfebf5fa79bd5e7ff85abcf7fbcacfb7fdf0a23cff1a0e87d554fd4bfa977ff997a383d1afbe7eebf5faf9871f7e78f3bac231934bd8df68e9a3eb9cfd6ae3f2c6c6743a3dd9785a2e97cfc3e1f0d575d84733f9f6d7453df171a3e99c436b616bbc035a6bdbd9ec57
2e7cd4fafdfef36030781e8fc72f5abfdfffd4c2ee42b2661daa5aa99f04941706c7feaef57afd3c9d4e0f5e80a5696a1a136f1a8fc7078f1da71e87d7b0e619b7efad35b27bbd5e15ec1f7bd1bfdbedaa60e4adf78035b7dbedd2e3e95ffff55fabff7faee0a889d929cfcfaf3f4bca1950f5afef4ff3ae7ffda33538f7ab
1ef77f5f19fa1d0a57eae7bccbe5b2fab94b2e3d70a85fefb5af062ff51de023e2f9effeeeef4e36c6b7dbed87635c204add7ea078cc52626f6d0e9ca669b5f6f0b1e36cbd5ebf3973f2d8aae6fdfd22ce704dd574cea1b5b0fde2f9f939e00cce3ab08aa288d96c16abd52af23c3fe79f8ac16010c3e130fafdfe59ff0ec7
db6c36b1d96cde7dfd0fbd5e455144966507bf3f4dd3180c0631180ca2d7eb9db4bfb4539665b15aad62b3d9bc39aede3a6e6c369b83ff5e8ec37ebf1f699a9eacaf5014c58b63675114afbea7d7eb1d3cfee5797ef0589b2449f4fbfde8f7fb31180c224992b3f49deb73c9f1f4f0f0109bcd2686c361cce7f3d33f98f8fd
79e562b1a81e4bafd78bf1781cc3e1f02c7ff3141e1f1f23cbb237cf85922489dd6e7753efcdc56211b3d9ecc5631a8d46f1effffeeff1bffffbbf077f264dd3d86eb79ffa3b4551c4643289c562f1e2dfc7e3714ca753c74c1a351a8daab179ecb12fcff3eabcf4bdf3cc43e32ecbb237c778795e7accb5f06ab58ad16814
455144afd78be572798ef3d95f9cfa1782609473b9d8c03a269cf88c24496230185401859396eb9665597502f0d689e821fd7ebf3a41f53af3bdea27a3ef05f0fbd2348d5eaf579d700ae5b994f2b89965d99b1744fb92247931660783c1057aca2df8ea78fa8bbff88bf8cd6f7e137ffee77f1efffddfff7df0fbb22c8bfb
fbfb888858afd767bd517de8c67b9224311c0e633c1e5fd5b9429665b1582c623e9f47511491e7f98be7bd7c2cd3e9f4266eeeef07a2fbcffb643289d96cf6eae77efcf1c7c8f3fc53af4d5114f1f0f070f0b3fad018db6c36f1f0f01011113ffffc73fcf6b7bf75cce4ec66b3594c269388f8fc8d9aa2285e9c97be1594ee
2bc3fef23af8d85033cff3984c26b15aad22e2dbf9ed7abd3ed7315330cac909463997460656194e9401d93127e7e59db3344dab0f016edb7b01e95b774ae1d48c436ecd7b9f99b710ac705d8e1d4fbff8c5b76bdcdd6ef7e6cda13214ebf57ab1dbed4edfd903de0aea86c361e337b1b22c8b878787582e97efbe3767b359
8cc7e30bf6ec73caf3f6c5627154107d7f7fff2accdc6eb79faa48cbb22cfafd7efccffffccfc1afef5f1b1745117ff5577f15fff55fff1511bfaf282d7f976326e754afc08cf876fef8d59b1defddb87fabfaf923799e57d5f6a5fa7be44c04a39c5ed373f9b5d6b6ab52aef1536f767d04006856b98ee47beb7a3e3d3d55
ebdd5d7af39f439b7f0e068346d7229fcfe707d7112d3d3d3d3d4fa7d3ab5d2f7db95cbeda68f098f50bb7dbed8b9ff9ec5ab0e5f3f6564bd3f4d5cf1cdafd1b2ee9d03e0b6fbdf79beed385d6cc6d3ae7d05ad81aef80d6da060000ef2a77bbdfdf0d7d5f7d47f52636ac99cfe7af36032ac3bc26fa736873a67ebfffdcef
f79f87c3e1d51500ec76bb839b68a669faa980f3d8f1b2efd0864afb6d3ff4ac8fb97af8034d28c3c8fa782c3704bb94ed767b3010bdf006c54de71c5a0b9ba9f49c8b810500c0bbcaf51b8f99265f6ec4d4eff763bd5e5fa8872fe5791e8bc5e2d50690699a56eb485e6af3bc435363af690a77b90efc6ab57ad1cf724397
4b2c4bf0de7aa2fbe6f379b58663b979ccfe94fb26c71e441c9ebe1e11d52649a7de3ba17cffee1ff31adca0ce547a4e4e30cab9185800007ce8a79f7e8aa2283e5c2f32cff3b8bfbf8fa2285e84584d59ad5655ab2b37f22c37d6ebca9ad2e5262f874294886fc14dd92e21cbb2f8877ff8876a7dd08fd4d7b92d43f87d82
51ae45f93e3bf45eab6f9e54eea5718cf2664bb957c76ab57ab18e6eb9716dbfdf6ff2f82b18e5e404a39c8b810500c0871e1f1f63b55ac5743afd70b3a07223a6244962b7db5d45e858ee007d28488868a69af452caaad0b2d5d543945357b17d64b158c43ffdd33fc56f7ffbdba3be3f4992787a7a8a8897bb81efbbe406
6070ac7223b3fdeaecba7283a55eaff7e2bd586e22f6decfd5dfc7574030cac909463917030b00800f9541d4603088e572f9e1f797bb930f87c398cfe717e8e1e7d483c2fdb0a10c0bcbb0f4d682d22ccbaaf65e085c56ac35a10ccf3fa3ac04cdf33cd2347d73d7fa88d73bd7c335c9f3bc3af694959ffbefd3f7d4ab4caf
f4668e609493138c722e061600001fcab22ceeefef23e2b8d0a95c97342262bd5e5fd5ba9afb3eaa262d03883250bcb6c752062c6565e8a1fe97fdeef7fb675f33f423ef557bbe673c1ec7743aad42f7f7b87ee6169515ddfb95dd6515691988de00c128272718e55c0c2c00008e72777717799e1f1d74965581bd5e2fb6db
edad5cd05701e35b416344541597656071a9b0b4ec4f3d08dd570f72afb19a6cb55ac5e3e3e3a77f6ebd5ec766b339aad2d4f533344a30cac909463917030b0080a38c46a3582c1655e5de478aa288bbbbbb288ae26aa7d41fa33e357db3d9bcda44a5540f24eb9ba97c6663953ccfabdf5f5f57b0feeffbca4ab25b9afa9f
e7798c46a383c1ee5b7efdeb5fc7dffeeddf1ef5bd1f6d12069c95609493138c722e0616000047592c16311a8d224dd3d86eb747fd4cbd3af01a76a93f85724dc0b2bd175abea50ced3e9a12beaf3ea5b6ac546d7a6afcf72883f6f7d60b8d88f8e52f7f197ff8877f78f4f375edcb3740cb09463939c128e7626001007094
a228e2a79f7e8a8888dd6e77742057dfa57ebd5eb7b6926f7f2395fdcacf6395815e92242fd6156c6bd0571445fcf55fff75fce77ffee79bdff3cb5ffe32fee33ffee3e8df2918854609463939c128e76260010070b4c7c7c758ad56319d4e633c1e1ffd730f0f0fb1d96c224dd358afd737b3dee83994d3e323e296365339
9b3238ffd33ffdd3f8cbbffccb4f57d11e22188546094639b93f68ba0300000065d8b45aad3ef573cbe5329224892ccbbeb423799bd47789ef7a285adf4ce9dffeeddf62bbddc6783c8e1f7ef8e1bb7f2f00ed21180500001a5706a39f9d1e9e24492c97cb88f8b6aee462b1384bffb81d455154ebcf0e0683180c06111131
9d4ee337bff98d8a4f002a82510000a071e59a97119faf1aedf7fbd5f4fbc964729229d3dcae878787288a22d2348df97cfee26bbd5e2fd6eb756cb7dbf8d5af7e15e3f1b8b56bd302f031c12800007015cacabeaf4c579e4ea7d1eff7a3288a188d469faa3aa53dca603c499298cfe76f2e2990a669fcfddfff7d4ca7d3d8
6eb7b1dbed623e9fc72f7ff9cbf8e33ffee30bf71a80a6d87c897331b00000f8943ccfe3eeee2e22229e9e9e3ebd4e665114717777174551c470387c552d48bb2d168b188d461111319fcf63381c7efa77dcdddd459ee7f1cffffccff17ffff77f9165d98ba07e3018544b37001767f3254e4e30cab9185800007cdafdfd7d
6459f6e5606bb3d9c4c3c34344c4a777b8e7766559564da11f8fc7319d4e3ffd3bde0ae68ba288cd66135996c5603030f51e9a2318e5e44ca5070000ae467d13a6affebcf546bba5be7c42bfdfff52281a11d5c65d83c1e045b572922431180c623a9d0a45015a46300a00005c8d729dd1cf6ec05457ae371a11f1f8f87815
eb8d6e369b188d46f1d34f3f7d690d55de361a8daa7545bf679a7b39e6ec5a0fd01d82510000e06aa4691abd5e2f8aa2f8ae7074b95c46afd78b3ccfab75279b32994c623299c462b1b88a90b64d46a351354ed6ebf5a7d7a52d655916799e4792245f5ac20180db2418050000aeca29aa46ebd583abd5aad170743a9d7e79
7a376f1b8d46d5f4f7f97cfe5dd3dccbb1568e3d00ba41300a00005c95b2626fb55a7d5785659aa6d5cef4f51dcbb97db3d9ec4528fabd559ea6d103749360140000b82abd5eafaafe2bc3afaf1a0e87c2d196592c1631994c22e274a168398d5ec52840b7fc51d31d000000d8371c0eabf523cb5de6bfe77745bc9e7a7dad
cacd99d2347db566669ee791e7f98b7febf7fb07ff3d499248d3348aa2882ccb22e25be8dcebf55efdcdf27bdefa7afdfbca3e9561e257d7f5fc8a7ab83d1c0e4fb21e68f97c0b4501ba47c52800007075ca902acbb22ad4fb1ed75e395a14454c2693787c7c8c2ccb62b3d9c4dddd5d3c3c3cbcd8c5be288a787c7c8c8787
87175f2b37992aff7db158bc78de56ab553c3c3cbc0a4f8ba288d1681493c924f23c8fc964127777772fd677cdb22c66b3593c3e3ec6dddd5d6c369beafb7efae9a78b6d28555f2bb6fe7a7e8ffa265f365d023952b3490000142c49444154e81ec12800007075eabb837fef74fad2b586a3455154a1e572b98cf1781cd3e9
34d6eb75645956059d11dfaa48eb958de5a64efd7eff455058afa62ca7880f87c3176b68967f3749926a4afa72b98c2449e2f1f1b10a5d57ab55d58aa288d96cf662b983fdb0f51cb22c3b79281af1fb756ceb8f0780ee108c02000057e914bbd3efbbc670b4ac12dd5f32204dd32af82c2b3a23e2c5f7d5ab49eba1e7fe73
9665d9ab8ac8d16874f0dfcbdf339bcd22e25bf85a0f63cbd075bd5ec76eb73b7ba05886c34551bcd850eb14cac059b52840370946010080abd4eff7a3d7eb45511427ab1a8db8ae70b49c361f110703c632b0ab3f07f5eac67a00bad96c0efe7bc4b7aacefaefcff3bcfa9efa14fc878787eadfeba16bfd67cb3545932479
773dd253d80f45d7ebf5497f77b9dc806014a09b04a30000c0d52a2b15eb21dd295c4b387acce32a2b38eb6b86d6ab69cb353e379b4d2c97cb887819a46659f62a74ad07a7ebf5fa45dbed76f1fcfc1ccfcfcfdff1c8bedf62b188fbfbfb17a1e829377aaa578b5e72032900ae8760140000b85a6525df6ab53af95a96d710
8e1eb371d1a1aacc32182d370f2a9f9b5eaf5705a9f53542f7775cbfd486495f35994caad76330189c3c14ad6fba64377a80ee128c02000057ab1ef49d723a7da9e970b4be2ee85bca40b05ef5599f4ebfd96c62b158542172bd9a34cff3288ae255a8580f5bdfab5abdc4c64a754551c46834aad6371d8fc7d58650a754df
74e998d7008076128c02000057ed1c9b30d5ed87a38f8f8f17aba8ac879d6f05bfe514fafde9f0fbcf4b19760e06832a487c7c7c7cb5a953fd7b237ebfc9d2befa864f975014453c3c3c54cfc37c3eaf369f3ab5f26f1c7a6e00e80ec128000070d5ca3520f33c3f4bd568f937ca7074b55ac5fdfdfd8b353dcf2549922a9c
3b14501645516daab43fe5bbbe61d0fee648e5f7beb54152bfdf7f51713a1a8d5e84c18bc522b22cbb5835659665717777175996459224b15eafcfb621d266b3a9fe8e69f400dd2618050000ae5e1992bd55dd78aabfb15eafa3d7eb459ee7717f7f1f93c9e46c7faf349d4e63381c469ee7af1edf6c368b2449aad0b6ae0c
f67abddeab80af0c34df0bfee6f3795559ba582ce2eeee2e1e1e1ee2fefe3e168b45b591d3b9ad56ab573bcf9f3390adaf2d6ad325806efb45d33b0dd25a0616000027531445dcdddd455114670fceca752ecb00addfefc77c3e3f5879798cc964128bc5a2aac84cd334fafdfeab69e2abd5aa5a17b4dfef479ee75545e95b
7fbbfcbd87a684dfdfdfc776bb7db76f65185b5f73733018c4783cae42c3c964f26283a7b7faff1593c9a40a83cfb1f3fcbe3ccfe3eeee2e2222b6dbedabe50980abf68ba63b40fb08463917030b0080932a43b47ebf1febf5faec7f6fb158c46432a9362f9acfe7a65e9f489665311a8daae50aea4b199cd368348ac56271
b131049c94609493138c722e061600002755aff63b77d568693fc01b8fc72faa29f9bc7a956859117b894d908aa2889f7efa29222e377e8093128c7272d6180500006e42afd7abd61a3dd7264cfbd2348ded76fb6283a48787878b6cccd4365996c5fdfd7d158af6fbfd17cfedb9d5ffae5014800815a39c8f810500c0c9d5
ab4677bbdd97d7fdfc8acd66138f8f8fd55aa1d3e9f462a1deaddbaf122d379cba94fa1ab5cbe5d29208709b548c72722a460100809b51df81fd9c3bd41fd2eff763b7db55d58693c924eeeeee2e56bd7a8bcaddeecbd76a3018c46eb7bb68281af16dacd4379702800815a39c8f810500c0596c369b7878788888cb578d96
66b35915b6457c0b6cc7e3f1c503bf6bb5582c62369b553bd937b97955bd5a743e9f7b8de076a918e5e4548c02000037a5be466453d59ae3f13876bb5db511539ee7311a8d3a5f415a56888e46a3c8f3bcda5c69b7db3556a9b95aadaa6a51a12800752a463917030b0080b329ab46932489dd6ed7e82ef14551c46c368bc5
62f1a282743018746207fba22862b55abdaa101d0e8757f1f8efeeee22cf73d5a270fb548c72728251cec5c00200e0accac06b3c1ec7743a6dba3b5540ba5aad5e04846540dac494ff73caf33c168bc58b40f89a02d1886f4b1e4c26934892249e9e9e9aee0ef07d04a39c9c60947331b0000038abd56a158f8f8f11d1dc5a
a36f2903c32ccbaa7f1b0e8731180caa65006e559ee755856ca95c637530185c45201af1726dd1e9741ae3f1b8e92e01df4730cac909463917030b0080b37b787888cd661383c12096cb65d3dd7965b3d9c46c368bcd6653fd5b9aa631180c6230185c5598fb9e72bafc7ed8dbeff7abc0f7da4c269398cd66d1ebf562b7db
35dd1de0fb09463939c128e76260010070765996c5fdfd7d4444acd7ebabadc63c546519115505e9b5ae7db95aadaa5677edd5af799ec7dddd5d44442c97cbab0c6e814f138c72728251cec5c00200e02246a3512c168b48d334b6db6dd3dd79d75b9597e55aa4d71036665956f5b15c3b34e2f795aec3e1f06aa6cbbfe5f1
f13156ab55f4fbfd58afd74d7707380dc128272718e55c0c2c00002ea2be96e42ded3c5e6e5e54dfac29e2db7a9dfd7ebffadf344dcfde8fcd66135996c566b379d59732b03d773f4e65b3d9c4c3c34344446cb7db9be937f021c128272718e55c0c2c00002ea6befbf86eb7bbfa8ac67d5996552169bd4a33e25b35691990
a669fadd15a565005afeefa1bf5756aedee214f472ddd9e17018f3f9bce9ee00a72318e5e404a39c8b810500c045dddddd459ee7311e8f633a9d36dd9d2fdb6c3655e5e6a1e032e25b785956422649f26213a72449aa9fc9f3bcfaef2ccb0efeae88a882d77ebfdff854feefb1582c62341a459224b1dd6e6f66732be02882
514e4e30cab9185800005c547d0af56eb76b4d2856aff0ccb2ecc554f7afa857a05e62aafea5144511f7f7f7ad08c7818304a39c9c60947331b00000b8b8721a75db37dda9577fe6795e85a545514451145528bc5f59da9610f490c96412b3d92c7abd5e6cb7db9b5b4e01f890609493138c722e061600001797e779dcdddd
4544c47abdbee969e11c2fcbb2b8bfbf8f8888e57279936ba3021f128c72727fd074070000004ea5d7ebc5783c8e8888d168d4706fb894f2b51e0c064251008e26180500005a653c1e47922491e7794c2693a6bbc3994d2693c8b22c9224b10b3d009f22180500005aa51e90cd66b358ad560df78873d96c36319bcd222262
3e9f5b5714804fb1c628e762600100d0a872339e244962bbddb666977abea9ef423f180c62b95c36dd25e0bcac31cac909463917030b0080c6dddfdf479665addfa5be8beac1f76eb7532d0aed2718e5e44ca50700005aab9c5ebdd96cac37da22a6d003700a2a463917030b0080abb0582caa5dcbd7eb75f4fbfd867bc4f7
a84fa11f0e87365c82ee5031cac909463917030b0080abf1f8f818abd52a7abd5e6cb75b1586376c341ac562b1f05a42f70846393953e9010080d69bcfe7d1ebf522cff3aa7a94db33994c62b158448429f4007c3fc1280000d07a499254bb96af56ab6a7d4a6ec762b178b1aea8251100f85ea6d2732e061600005767369b
559b306db7db48d3b4e11e718c2ccbe2e1e1218aa2b0ae287497a9f49c9c60947331b00000b84a0f0f0fb1d96c224dd358afd7a6635fb9fa664bfd7e3fd6eb75d35d029a2118e5e404a39c8b810500c0552a8a22eeeeeea2280ae1e80db8bfbf8f2ccb6cb604084639396b8c0200009d9224491586d6a768737d46a3516459
56ad112b1405e09404a3000040e7d42b4585a3d769369bbdd881de7ab0009c9a60140000e8a4fd7074341a35dd257e67b158549b644da7d3180c060df7088036128c0200009d550f4757ab9570f40a2c168bea75180e87311e8f1bee11006d25180500003a2d4dd3984ea711f13294e3f2f643d1f97cde708f006833c12800
00d079f5104e38da0ca1280097261805000008e168932693895014808b138c020000fcce2d84a35996459ee79ffada7b3fd3b4d16814b3d92c2222c6e3b15014808bf9a3a63b000000704d86c361447c0bec168b4544c4d584755996c5fdfd7d244912bbdd2e9224f9f06beffd4cd3f69fe3f2b907804b50310a0000b067bf
72f4fefe3e8aa268b857114992449224d1ebf55e059c6f7dedbd9f6992501480a6fde2f9f9b9e93ed04e06160000376fb55ac568348aa22822499258afd791a669d3ddba69799ec7e3e363645916114251e068bf68ba03b48f8a51000080370c06832a0c2d8a22eeefefab2a473e6fb55ac5fdfd7d6459164992c472b9148a
02d01815a39c8b810500406b144511a3d12856ab5544d839fd2b269349b5c9529aa6b15c2ea3d7eb35dc2be086a818e5e404a39c8b81050040ebec877bebf5faaad6edbc464551c4e3e3636c369b88f8162a4fa753cf1bf05982514ece547a000080234da7d3582e97912449645916777777551529af6d369bb8bfbf8fcd66
134992c47c3e8ff97c2e1405e02aa818e55c0c2c00005a2bcbb2787c7c8c3ccf2322a2dfefc77c3e3735fc778aa288c96452adc7daebf562b95cdab80af81e2a46393915a30000009f94a6696cb7db188fc711f1fbcac8729a7d972d168bb8bbbbab42d1f1781cdbed56280ac0d55131cab9185800007442966531994caa35
34d3348de9741afd7ebfe19e5d96e701383315a39c9c60947331b00000e894d96c16b3d92c8aa28888ee4cafcff33c66b35955211af1ad4a743a9d36d82ba08504a39c9c60947331b00000e89cfdb53523dabb0b7b511455205a86c1c3e130c6e371ebc360a01182514e4e30cab91858000074569ee7311a8daa69e5499254
a1611b02d2c5621193c9e44575ec783c366d1e3827c128272718e55c0c2c00003a6fb3d9c46432892ccb22e2dbeeec83c1e02603d2a22862b55ac56c368b3ccf23e2dbe3994ea731180c1aee1dd00182514e4e30cab918580000f03b8bc5e245a098244915905efbb4f33ccf63b158bc98329f24498cc7e3188fc70df70ee8
10c128272718e55c0c2c0000d853068c650569c4f54e43df6c36b15aad5eac97daebf5623c1ec76030b8b98a57e0e609463939c128e762600100c01b369b4d2c168b58ad56d5bf5d4be8f856783b1c0e4d99079a2418e5e404a39c8b810500001f38344d3de25b1059b6344dcfda872ccb62b3d94496652f82da08bbcc0357
4530cac909463917030b00008e541445159096eb9096caf548d3343d4935695114b1d96caab6fff76e798328a0d504a39c9c60947331b00000e00bf23c7f115cd62b492322d234ad02cbb29ab4d7ebbdaaeaccf3bc0a3df33c8fa228a2288a1753e44bf5e055752870a504a39c9c60947331b00000e004ea21e9a150f32bd2
347d315d1fe00608463939c128e762600100c089d52b3eeb15a1e5bf9555a165d56759519a2449f5dff58a53801b2218e5e404a39c8b81050000009c8a609493fb83a63b00000000007069825100000000a07304a30000000040e708460100000080ce118c02000000009df3474d7780d6b25b1c00000000574bc528000000
00d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc128
00000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e8
1cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e60140000
0000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e60
1400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000
748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00
000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47
300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000
003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e708460100000080ce118c02000000009d231805
000000003a47300a00000000748e601400000000e81cc12800000000d039825100000000a07304a30000000040e7fc3feab420bd3718d4e10000000049454e44ae426082}
  \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_sample_lattice}1{\*\bkmkend BMfig_sample_lattice}: An example candidate word lattice for the production \ldblquote I can\rquote t move my [v\u201?\u8216?\u201?\u170?] hand.\rdblquote }{\field{\*\fldinst TC "1 An example candidate word lattice for the production \ldblquote I can\rquote t move my [v\u201?\u8216?\u201?\u170?] hand.\rdblquote " \\f f}{\fldrslt }}\par
}\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb360 \fi0 {\*\bkmkstart BMsub_phonological_similarity}2.5{\*\bkmkend BMsub_phonological_similarity}  Phonological Similarity\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 At this point in the process, we have the following information about each erroneous production: a best-guess orthographic transcription of what the individual actually produced, and a ranked list of plausible lexical that they could potentially have been attempting to produce, together with probability estimates for each production. Recall that our goal is to determine whether the erroneous production was a phonemic paraphasia or an abstruse neologism. In order to make this determination, we must know whether the subject\rquote s utterance is phonemically related to any of the plausible target words.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Determining phonemic similarity can be done in a number of ways. In this work, we compute several different metrics of phonological similarity, and then use the resulting scores as inputs to a classifier. These methods fall into two general categories: rule-based and statistical.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Many aphasia assessment instruments include strict rule-based guidelines on how to determine phonological similarity. For example, the scoring instructions for the Philadelphia Naming Test (PNT) include detailed rules that take into account the number of shared phonemes and syllables that two productions may have in common 
[{\field{\*\fldinst{\lang1024 REF BIB_Roach_1996sp \\* MERGEFORMAT }}{\fldrslt{{Roach et al.}1996}}}
]. The annotation standards used by the AphasiaBank project also include an algorithm for determining if two words are phonologically related or not. As an example of one of the AphasiaBank rules, monosyllabic productions with an onset, vowel nucleus, and coda must match two of the three elements of a target word in order to be considered phonologically similar 
[{\field{\*\fldinst{\lang1024 REF BIB_MacWhinney_2000aa \\* MERGEFORMAT }}{\fldrslt{{MacWhinney}2000}}}
]. Both the PNT and the AphasiaBank rule sets are designed to optimize for coding consistency and ease of use on the part of linguistically informed human annotators.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 As described in section\~{\field{\*\fldinst{\lang1024 REF BMsub_related_work \\* MERGEFORMAT }}{\fldrslt{4.1}}}, besides rule-based phonological similarity metrics, there exist variety of statistical approaches for determining phonological similarity. In this work, we employ an edit-distance based metric that uses phoneme category rules, and assigns smaller substitution costs to replacement of \ldblquote similar\rdblquote  phonemes (i.e., a substituting one unvoiced fricative for another unvoiced fricative will cost less than substituting an unvoiced fricative for a voiced stop).\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 We first convert our best-guess orthographic representation of the subject\rquote s non-lexical production to an estimated phonological representation using the Phonetisaurus grapheme-to-phoneme toolkit 
[{\field{\*\fldinst{\lang1024 REF BIB_Novak_2011aa \\* MERGEFORMAT }}{\fldrslt{{Novak et al.}2011}}}
]. Next, we compute the phonologically-aware edit distance for each (production,candidate target) pair, and also apply the Philadelphia Naming Test phonological similarity rules. We use the CMU Pronouncing dictionary to obtain phonetic representations of the candidate target words.\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 At this point, we now have, for each error, a ranked list of plausible candidate target words, along with probability and phonological similarity scores for each candidate. We are now ready to attempt to classify the errors.\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_ranking_scoring}2.6{\*\bkmkend BMsub_ranking_scoring}  Classification, Re-ranking, & Evaluation\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 To determine the category of our error productions\emdash  again, between productions representing phonological errors such as \ldblquote [d\u201?\u8216?\u201?\u170?no\u202?\u352?s\u201?\u8221?\u201?\u185?]\rdblquote  for \ldblquote dinosaur\rdblquote , and productions representing abstruse neologisms\emdash  we trained a binary classifier using features representing the characteristics of the candidate target word space surrounding the erroneous production. Our intuition was that phonemic errors were much more likely than abstruse neologisms to have highly-ranked candidate target words that were also phonologically similar to the subject\rquote s actual production. We used the Scikit-learn Python machine learning library 
[{\field{\*\fldinst{\lang1024 REF BIB_scikit_learn \\* MERGEFORMAT }}{\fldrslt{{Pedregosa et al.}2011}}}
] to train a Support Vector Machine classifier,{\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} Our choice of classifier was driven largely by a desire for simplicity and a need for a classifier that could easily accomodate both continuous and categorical features.}
 and our features were a concatenated vector of, for each of the {{\i n}}-best candidate target words: \par
{\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs22\sl240\slmult1 \sb50 \li600\fi-300 1.\tab
The forward probability of the candidate (normalized across the {{\i n}}-best candidates); \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs22\sl240\slmult1 \sb50 \li600\fi-300 2.\tab
The candidate\rquote s phonological similarity to the production, according to the AphasiaBank guidelines \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs22\sl240\slmult1 \sb50 \li600\fi-300 3.\tab
The candidate\rquote s phonological similarity to the production, according to the PNT guidelines \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs22\sl240\slmult1 \sb50 \li600\fi-300 4.\tab
The candidate\rquote s phonologically-informed edit distance from the production \par
}\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi340 We performed leave-one-out cross-validation of our classifier across \par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 {\*\bkmkstart BMsec_results}3{\*\bkmkend BMsec_results}  Results\par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb300 \fi0 {\*\bkmkstart BMsec_discussion}4{\*\bkmkend BMsec_discussion}  Related Work & Discussion\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 While our results were \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_related_work}4.1{\*\bkmkend BMsub_related_work}  Related work\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 As far back as Shannon\rquote s word-guessing game 
[{\field{\*\fldinst{\lang1024 REF BIB_Shannon_1951p5641 \\* MERGEFORMAT }}{\fldrslt{{Shannon}1951}}}
], researchers have sought to leverage the statistical regularities in natural language to predict missing or subsequent words. In practice, however, this proves to be a surprisingly challenging problem. Language occurs at levels beyond simply choosing lexical items, and local statistical characteristics of language often fail to capture syntactic and semantic patterns. Zweig & Burges {zweig-burges:2012:WLM} provide an enlightening discussion on the limitations of relying on n-gram guessing for syntactically complex tasks such as \ldblquote identify the missing word in the sentence,\rdblquote  and also describe a very challenging language model evaluation task built around this problem. They tested a variety of language modeling approaches using their task, and report that well-trained generative n-gram models achieve correct predictions {{\u8776*}30%} of the time,{\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} A finding that we can corroborate with the results presented in this paper.}
 while approaches using Latent Semantic Analysis
[{\field{\*\fldinst{\lang1024 REF BIB_Deerwester_1990vi \\* MERGEFORMAT }}{\fldrslt{{Deerwester et al.}1990}}}
] can achieve scores in the mid-40s. State-of-the-art performance on the their word prediction task typically use recurrent neural network langage models,{\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs22{\cs62\super\chftn} See De Mulder et al. {DeMulder:2015dy} for a recent review on this subject.}
 and the best scores are in the mid-{50%} range 
[{\field{\*\fldinst{\lang1024 REF BIB_mirowski_vlachos_2015_ACL_IJCNLP \\* MERGEFORMAT }}{\fldrslt{{Mirowski and Vlachos}2015}}}, {\field{\*\fldinst{\lang1024 REF BIB_NIPS2013_5165 \\* MERGEFORMAT }}{\fldrslt{{Mnih and Kavukcuoglu}2013}}}
]. \par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 In our case, the nature of our data renders this task even more challenging. Our sentences are often short and agrammatical (often missing or mis-using determiners, for example), and are produced by individuals with impaired language ability. \par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Using phonemic similarity to identify potential lexical items: 
[{\field{\*\fldinst{\lang1024 REF BIB_Han_Baldwin_11 \\* MERGEFORMAT }}{\fldrslt{{Han and Baldwin}2011}}}, {\field{\*\fldinst{\lang1024 REF BIB_Choudhury_2007_IMS_1326044_1326048 \\* MERGEFORMAT }}{\fldrslt{{Choudhury et al.}2007}}}
] - much related work in the text normalization literature 
[{\field{\*\fldinst{\lang1024 REF BIB_Sproat_2001p5321 \\* MERGEFORMAT }}{\fldrslt{{Sproat et al.}2001}}}
]\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \fi340 Computational analysis of aphasic speech: tends to either involve computational analysis of carefully annotated data, or looks at higher-level syntactic features rather than low-level lexical analysis as in our work. Using aphasiabank 
[{\field{\*\fldinst{\lang1024 REF BIB_MacWhinney_2011er \\* MERGEFORMAT }}{\fldrslt{{MacWhinney et al.}2011}}}
] automatic sub-typing from narrative transcripts
[{\field{\*\fldinst{\lang1024 REF BIB_Fraser_2014bg \\* MERGEFORMAT }}{\fldrslt{{Fraser et al.}2014b}}}
] statistical parsing to detect
[{\field{\*\fldinst{\lang1024 REF BIB_fraser_EtAl_2014_W14_34 \\* MERGEFORMAT }}{\fldrslt{{Fraser et al.}2014a}}}
] Syntactic analysis of same: 
[{\field{\*\fldinst{\lang1024 REF BIB_Goodglass_1994dp \\* MERGEFORMAT }}{\fldrslt{{Goodglass et al.}1994}}}
] Segmentation of aphasic speech: 
[{\field{\*\fldinst{\lang1024 REF BIB_fraser_EtAl_2015_NAACL_HLT \\* MERGEFORMAT }}{\fldrslt{{Fraser et al.}2015}}}
]\par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 {\*\bkmkstart BMsec_conclusions}5{\*\bkmkend BMsec_conclusions}  Conclusion & Future Work\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Limitations: - We are only using sentences with 1 error- excluding sentences with >1 error (N = 1,866) - more generally, we don\rquote t have a clean idea of how/whether sentences with multiple errors are different from mono-error sentences - open question for future work: are paraphasic errors within a sentence related to one another in some way? - our general finite-state approach can be generalized to sentences with additional errors, and we will explore such possibilities in future work!\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsub_future_work}5.1{\*\bkmkend BMsub_future_work}  Future Work\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Future work: - better LM, better phonology, etc. etc. - interpolation between omnibus and task-specific LMs - using backward probability as well as forward probability - using PoS/syntax to help word prediction - subject-level adaptation: using characteristics of the subject and their language to help identify erroneous productions - use of surprisal\par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 Acknowledgments\par
\pard\plain\s0\qj\widctlpar\f0\fs22\sl240\slmult1 \sb60 \fi0 Autism R01, Google, and Gerasimos\rquote s R03 (NIDCD 1R03DC014556-01A1)\par
{\pard\plain\s61\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\plain\b\fs32 References}\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \sb60 \li450\fi0 [{\v\*\bkmkstart BIB_Berndt_2000aa}{Berndt et al.}2000{\*\bkmkend BIB_Berndt_2000aa}]\tab
R\~Berndt, S\~Wayland, E\~Rochon, E\~Saffran, and M\~Schwartz. 2000. {\i Quantitative production analysis: A training manual for the analysis of aphasic sentence production}. Psychology Press.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Blei_2003_LDA_944919_944937}{Blei et al.}2003{\*\bkmkend BIB_Blei_2003_LDA_944919_944937}]\tab
David\~M Blei, Andrew\~Y Ng, and Michael\~I Jordan. 2003. {Latent Dirichlet Allocation}. {\i J. Mach. Learn. Res.}, 3:993\endash 1022, March.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Brookshire_2014fa}{Brookshire et al.}2014{\*\bkmkend BIB_Brookshire_2014fa}]\tab
C\~Elizabeth Brookshire, Tim Conway, Rebecca\~Hunting Pompon, Megan Oelke, and Diane\~L Kendall. 2014. {Effects of Intensive Phonomotor Treatment on Reading in Eight Individuals With Aphasia and Phonological Alexia}. {\i American Journal of Speech-Language Pathology}, 23(2):S300\endash S311, May.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Brysbaert_2009du}{Brysbaert and New}2009{\*\bkmkend BIB_Brysbaert_2009du}]\tab
Marc Brysbaert and Boris New. 2009. {Moving beyond Kucera and Francis: a critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English.} {\i Behavior research methods}, 41(4):977\endash 990, November.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Choudhury_2007_IMS_1326044_1326048}{Choudhury et al.}2007{\*\bkmkend BIB_Choudhury_2007_IMS_1326044_1326048}]\tab
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. {Investigation and modeling of the structure of texting language}. {\i Int. J. Doc. Anal. Recognit.}, 10:157\endash 174, December.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_doi_10_1080_02687030244000707}{Cruice et al.}2003{\*\bkmkend BIB_doi_10_1080_02687030244000707}]\tab
Madeline Cruice, Linda Worrall, Louise Hickson, and Robert Murison. 2003. {Finding a focus for quality of life with aphasia: Social and emotional health, and psychological well-being}. {\i Aphasiology}, 17(4):333\endash 353.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_DeMulder_2015dy}{De\~ {}Mulder et al.}2015{\*\bkmkend BIB_DeMulder_2015dy}]\tab
Wim De\~Mulder, Steven Bethard, and Marie-Francine Moens. 2015. {A survey on the application of recurrent neural networks to statistical language modeling}. {\i Computer Speech {&} Language}, 30(1):61\endash 98, March.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Deerwester_1990vi}{Deerwester et al.}1990{\*\bkmkend BIB_Deerwester_1990vi}]\tab
Scott\~C Deerwester, Susan\~T Dumais, Thomas\~K Landauer, George\~W Furnas, and Richard\~A Harshman. 1990. {Indexing by latent semantic analysis}. {\i JASIS}, 41(6):391\endash 407.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Dell_1997wj}{Dell et al.}1997{\*\bkmkend BIB_Dell_1997wj}]\tab
G\~S Dell, M\~F Schwartz, N\~Martin, E\~M Saffran, and D\~A Gagnon. 1997. {Lexical access in aphasic and nonaphasic speakers.} {\i Psychological review}, 104(4):801\endash 838, October.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Dell_1986vk}{Dell}1986{\*\bkmkend BIB_Dell_1986vk}]\tab
G\~S Dell. 1986. {A spreading-activation theory of retrieval in sentence production.} {\i Psychological review}, 93(3):283\endash 321, July.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Engelter_2006da}{Engelter et al.}2006{\*\bkmkend BIB_Engelter_2006da}]\tab
Stefan\~T Engelter, Michal Gostynski, Susanna Papa, Maya Frei, Claudia Born, Vladeta Ajdacic-Gross, Felix Gutzwiller, and Phillipe\~A Lyrer. 2006. {Epidemiology of aphasia attributable to first ischemic stroke: incidence, severity, fluency, etiology, and thrombolysis.} {\i Stroke; a journal of cerebral circulation}, 37(6):1379\endash 1384, June.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Fergadiotis_2015gp}{Fergadiotis et al.}2015{\*\bkmkend BIB_Fergadiotis_2015gp}]\tab
Gerasimos Fergadiotis, Stacey Kellough, and William\~D Hula. 2015. {Item Response Theory Modeling of the Philadelphia Naming Test.} {\i Journal of Speech, Language, and Hearing Research}, 58(3):865\endash 877, June.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_fraser_EtAl_2014_W14_34}{Fraser et al.}2014a{\*\bkmkend BIB_fraser_EtAl_2014_W14_34}]\tab
Kathleen\~C Fraser, Graeme Hirst, Jed\~A Meltzer, Jennifer\~E Mack, and Cynthia\~K Thompson. 2014a. {Using statistical parsing to detect agrammatic aphasia}. In {\i Proceedings of BioNLP 2014}, pages 134\endash 142, Baltimore, Maryland, June. Association for Computational Linguistics.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Fraser_2014bg}{Fraser et al.}2014b{\*\bkmkend BIB_Fraser_2014bg}]\tab
Kathleen\~C Fraser, Jed\~A Meltzer, Naida\~L Graham, Carol Leonard, Graeme Hirst, Sandra\~E Black, and Elizabeth Rochon. 2014b. {Automated classification of primary progressive aphasia subtypes from narrative speech transcripts.} {\i Cortex; a journal devoted to the study of the nervous system and behavior}, 55:43\endash 60, June.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_fraser_EtAl_2015_NAACL_HLT}{Fraser et al.}2015{\*\bkmkend BIB_fraser_EtAl_2015_NAACL_HLT}]\tab
Kathleen\~C Fraser, Naama Ben-David, Graeme Hirst, Naida Graham, and Elizabeth Rochon. 2015. {Sentence segmentation of aphasic speech}. In {\i Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 862\endash 871, Denver, Colorado, May. Association for Computational Linguistics.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Frisch_wh}{Frisch and Wright}2002{\*\bkmkend BIB_Frisch_wh}]\tab
Stefan\~A Frisch and Richard Wright. 2002. {The phonetics of phonological speech errors: An acoustic analysis of slips of the tongue}. {\i Journal of Phonetics}, 30(2):139\endash 162.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Gaete_2008jr}{Gaete and Bogousslavsky}2008{\*\bkmkend BIB_Gaete_2008jr}]\tab
Jorge\~Moncayo Gaete and Julien Bogousslavsky. 2008. {Post-stroke depression.} {\i Expert review of neurotherapeutics}, 8(1):75\endash 92, January.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Goodglass_1997ys}{Goodglass and Wingfield}1997{\*\bkmkend BIB_Goodglass_1997ys}]\tab
Harold Goodglass and Arthur Wingfield. 1997. {\i Anomia: Neuroanatomical and cognitive correlates}. Foundations of Neuropsychology. Academic Press.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Goodglass_1994dp}{Goodglass et al.}1994{\*\bkmkend BIB_Goodglass_1994dp}]\tab
Harold Goodglass, Julie\~Ann Christiansen, and Roberta\~E Gallagher. 1994. {Syntatic constructions used by agrammatic speakers: Comparison with conduction aphasics and normals.} {\i Neuropsychology}, 8(4):598\endash 613.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Han_Baldwin_11}{Han and Baldwin}2011{\*\bkmkend BIB_Han_Baldwin_11}]\tab
Bo\~Han and Timothy Baldwin. 2011. {Lexical normalisation of short text messages: Makn sens a {#}twitter.} In {\i Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics}, pages 368\endash 378, Portland.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Hula_2015kz}{Hula et al.}2015{\*\bkmkend BIB_Hula_2015kz}]\tab
William\~D Hula, Stacey Kellough, and Gerasimos Fergadiotis. 2015. {Development and Simulation Testing of a Computerized Adaptive Version of the Philadelphia Naming Test.} {\i Journal of Speech, Language, and Hearing Research}, 58(3):878\endash 890, June.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Kendall_2013hm}{Kendall et al.}2013{\*\bkmkend BIB_Kendall_2013hm}]\tab
Diane\~L Kendall, Rebecca\~Hunting Pompon, C\~Elizabeth Brookshire, Irene Minkina, and Lauren Bislick. 2013. {An Analysis of Aphasic Naming Errors as an Indicator of Improved Linguistic Processing Following Phonomotor Treatment}. {\i American Journal of Speech-Language Pathology}, 22(2):S240\endash S249, May.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_doi_10_1080_02687038_2014_973359}{Kristensson et al.}2015{\*\bkmkend BIB_doi_10_1080_02687038_2014_973359}]\tab
Joana Kristensson, Ingrid Behrns, and Charlotta Saldert. 2015. {Effects on communication from intensive treatment with semantic feature analysis in aphasia}. {\i Aphasiology}, 29(4):466\endash 487.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_MacWhinney_2011er}{MacWhinney et al.}2011{\*\bkmkend BIB_MacWhinney_2011er}]\tab
Brian MacWhinney, Davida Fromm, Margaret Forbes, and Audrey Holland. 2011. {AphasiaBank: Methods for Studying Discourse.} {\i Aphasiology}, 25(11):1286\endash 1307.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_MacWhinney_2000aa}{MacWhinney}2000{\*\bkmkend BIB_MacWhinney_2000aa}]\tab
Brian MacWhinney. 2000. {\i {The CHILDES Project: Tools for Analyzing Talk}}. Lawrence Erlbaum Associates, Mahwah, NJ, 3rd edition.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Mayer_2003kp}{Mayer and Murray}2003{\*\bkmkend BIB_Mayer_2003kp}]\tab
Jamie Mayer and Laura Murray. 2003. {Functional measures of naming in aphasia: Word retrieval in confrontation naming versus connected speech}. {\i Aphasiology}, 17(5):481\endash 497, January.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Minkina_2015dz}{Minkina et al.}2015{\*\bkmkend BIB_Minkina_2015dz}]\tab
Irene Minkina, Megan Oelke, Lauren\~P Bislick, C\~Elizabeth Brookshire, Rebecca Hunting\~Pompon, Joann\~P Silkes, and Diane\~L Kendall. 2015. {An investigation of aphasic naming error evolution following phonomotor treatment}. {\i Aphasiology}, pages 1\endash 19, August.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Mirman_2010cd}{Mirman et al.}2010{\*\bkmkend BIB_Mirman_2010cd}]\tab
Daniel Mirman, Ted\~J Strauss, Adelyn Brecher, Grant\~M Walker, Paula Sobel, Gary\~S Dell, and Myrna\~F Schwartz. 2010. {A large, searchable, web-based database of aphasic performance on picture naming and other tests of cognitive function.} {\i Cognitive neuropsychology}, 27(6):495\endash 504, September.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_mirowski_vlachos_2015_ACL_IJCNLP}{Mirowski and Vlachos}2015{\*\bkmkend BIB_mirowski_vlachos_2015_ACL_IJCNLP}]\tab
Piotr Mirowski and Andreas Vlachos. 2015. {Dependency Recurrent Neural Language Models for Sentence Completion}. In {\i Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)}, pages 511\endash 517, Beijing, China, July. Association for Computational Linguistics.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_NIPS2013_5165}{Mnih and Kavukcuoglu}2013{\*\bkmkend BIB_NIPS2013_5165}]\tab
Andriy Mnih and Koray Kavukcuoglu. 2013. {Learning word embeddings efficiently with noise-contrastive estimation}. In C\~J\~C Burges, L\~Bottou, M\~Welling, Z\~Ghahramani, and K\~Q Weinberger, editors, {\i Advances in Neural Information Processing Systems 26}, pages 2265\endash 2273. Curran Associates, Inc.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_National_Institute_of_Neurological_Disorders_and_Stroke_2014la}{{{National Institute of Neurological Disorders and Stroke}}}2014{\*\bkmkend BIB_National_Institute_of_Neurological_Disorders_and_Stroke_2014la}]\tab
{{National Institute of Neurological Disorders and Stroke}}. 2014. {{NINDS}} aphasia information page. Technical report.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Nicholas_1993wl}{Nicholas and Brookshire}1993{\*\bkmkend BIB_Nicholas_1993wl}]\tab
L\~E Nicholas and R\~H Brookshire. 1993. {A system for quantifying the informativeness and efficiency of the connected speech of adults with aphasia.} {\i Journal of speech and hearing research}, 36(2):338\endash 350, April.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_doi_10_1080_02687038908249023}{Nicholas et al.}1989{\*\bkmkend BIB_doi_10_1080_02687038908249023}]\tab
Linda\~E Nicholas, Robert\~H Brookshire, Donald\~L Maclennan, James\~G Schumacher, and Shirley\~A Porrazzo. 1989. {Revised administration and scoring procedures for the Boston Naming test and norms for non-brain-damaged adults}. {\i Aphasiology}, 3(6):569\endash 580.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Novak_2011aa}{Novak et al.}2011{\*\bkmkend BIB_Novak_2011aa}]\tab
Josef Novak, Dong Yang, Nobuaki Minematsu, and Keikichi Hirose. 2011. Initial and evaluations of an open source wfst-based phoneticizer. Technical report, The University of Tokyo.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_scikit_learn}{Pedregosa et al.}2011{\*\bkmkend BIB_scikit_learn}]\tab
F.\~Pedregosa, G.\~Varoquaux, A.\~Gramfort, V.\~Michel, B.\~Thirion, O.\~Grisel, M.\~Blondel, P.\~Prettenhofer, R.\~Weiss, V.\~Dubourg, J.\~Vanderplas, A.\~Passos, D.\~Cournapeau, M.\~Brucher, M.\~Perrot, and E.\~Duchesnay. 2011. Scikit-learn: Machine learning in {P}ython. {\i Journal of Machine Learning Research}, 12:2825\endash 2830.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_rehurek_lrec}{{\u344R}eh{\u367u}{\u345r}ek and Sojka}2010{\*\bkmkend BIB_rehurek_lrec}]\tab
Radim {\u344R}eh{\u367u}{\u345r}ek and Petr Sojka. 2010. {Software Framework for Topic Modelling with Large Corpora}. In {\i {Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks}}, pages 45\endash 50, Valletta, Malta, May. ELRA. {\f3 http://is.muni.cz/publication/884893/en}.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Roach_1996sp}{Roach et al.}1996{\*\bkmkend BIB_Roach_1996sp}]\tab
April Roach, Myrna\~F Schwartz, Nadine Martin, Rita\~S Grewal, and Adelyn Brecher. 1996. {The Philadelphia Naming Test: Scoring and Rationale}. {\i Clinical Aphasiology}, 24:121\endash 133.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_RoarkOpenGRM}{Roark et al.}2012{\*\bkmkend BIB_RoarkOpenGRM}]\tab
Brian Roark, Richard Sproat, Cyril Allauzen, Michael Riley, Jeffrey Sorensen, and Terry Tai. 2012. The {OpenGrm} open-source finite-state grammar software libraries. In {\i Proceedings of the ACL 2012 System Demonstrations}, ACL \rquote 12, pages 61\endash 66, Stroudsburg, PA, USA. Association for Computational Linguistics.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Rochon_2000js}{Rochon et al.}2000{\*\bkmkend BIB_Rochon_2000js}]\tab
E\~Rochon, E\~M Saffran, R\~S Berndt, and M\~F Schwartz. 2000. {Quantitative analysis of aphasic sentence production: further development and new data.} {\i Brain and language}, 72(3):193\endash 218, May.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Shannon_1951p5641}{Shannon}1951{\*\bkmkend BIB_Shannon_1951p5641}]\tab
C\~Shannon. 1951. {Prediction and entropy of printed English}. {\i Bell System Technical Journal}, 30:51\endash 64.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_Sproat_2001p5321}{Sproat et al.}2001{\*\bkmkend BIB_Sproat_2001p5321}]\tab
Richard Sproat, Alan\~W Black, Stanley Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards. 2001. {Normalization of non-standard words}. {\i Computer Speech {&} Language}, 15(3):287\endash 333, July.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_vanDijk_2015gz}{van Dijk et al.}2015{\*\bkmkend BIB_vanDijk_2015gz}]\tab
Mariska\~J van Dijk, Janneke\~M de\~Man-van Ginkel, Th{\'f3}ra\~B Hafsteinsd{\'f3}ttir, and Marieke\~J Schuurmans. 2015. {Identifying depression post-stroke in patients with aphasia: A systematic review of the reliability, validity and feasibility of available instruments.} {\i Clinical rehabilitation}, page 0269215515599665, August.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_zweig_burges_2012_WLM}{Zweig and Burges}2012{\*\bkmkend BIB_zweig_burges_2012_WLM}]\tab
Geoffrey Zweig and Chris J\~C Burges. 2012. {A Challenge Set for Advancing Language Modeling}. In {\i Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT}, pages 29\endash 36, Montr{\'e9}al, Canada, June. Association for Computational Linguistics.\par
}}}
